{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "impaired-keeping",
   "metadata": {},
   "source": [
    "## Neuromorphic HAR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungry-membership",
   "metadata": {},
   "source": [
    "### By loading optimized (hyper)parameters and weights, the confusion matrices can be here obtained, together with memory and energy evaluations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-hopkins",
   "metadata": {},
   "source": [
    "#### <b>IMPORTANT NOTES:</b>\n",
    "<b>1)</b> for each network,  variables <b>optim_nni_experiment</b> and <b>optim_nni_trial</b> must be set accordingly to the IDs of the NNI optimization experiment and trial whose results are to be used;<br>\n",
    "<b>2)</b> in the case of the sCNN, these variables are used to keep the optimized structure parameters as for the <i>NON-SPIKING</i> counterpart. The NNI optimization experiment and trial IDs for the spiking CNN must be set through the variables <b>snn_nni_experiment</b> and <b>snn_nni_trial</b> respectively;<br>\n",
    "<b>3)</b> NNI experiment results (of each trial) can be found in:<br>\n",
    "&emsp;&emsp;{os.path.expanduser('~')}<br>\n",
    "&emsp;&emsp;&emsp;&emsp;|<br>\n",
    "&emsp;&emsp;&emsp;&emsp;| \\_ \\_ nni-experiments<br>\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;|<br>\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;| \\_ \\_  {experiment ID}<br>\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;|<br>\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;| \\_ \\_  trials<br>\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;|<br>\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;| \\_ \\_  {trial ID}<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "judicial-junior",
   "metadata": {},
   "source": [
    "<b>Hyperlinks to each network:</b><br>\n",
    "<b>[LSTM](#Section_1)</b><br>\n",
    "<b>[CNN](#Section_2)</b><br>\n",
    "<b>[sCNN](#Section_3)</b><br>\n",
    "<b>[LMU](#Section_4)</b><br>\n",
    "<b>[sLMU](#Section_5)</b><br>\n",
    "<b>[LMU (ff)](#Section_6)</b><br>\n",
    "<b>[sLMU (ff)](#Section_7)</b><br>\n",
    "[FLOPs calculation and energy estimation for LMU and LMU (ff)](#Section_8)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sublime-theory",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "rapid-reception",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-16 11:49:34.416921: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-09-16 11:49:35.968119: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/root/.mujoco/mujoco210/bin:/usr/lib/nvidia-520\n",
      "2023-09-16 11:49:35.978807: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/root/.mujoco/mujoco210/bin:/usr/lib/nvidia-520\n",
      "2023-09-16 11:49:35.978830: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-09-16 11:49:38.228490: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-09-16 11:49:38.966933: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/root/.mujoco/mujoco210/bin:/usr/lib/nvidia-520\n",
      "2023-09-16 11:49:38.979055: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/root/.mujoco/mujoco210/bin:/usr/lib/nvidia-520\n",
      "2023-09-16 11:49:38.979149: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-09-16 11:49:39.909718: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statistics\n",
    "import csv\n",
    "import itertools\n",
    "import json\n",
    "import random as rn\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from scipy.signal import butter, freqz\n",
    "\n",
    "import nengo\n",
    "import nengo_dl\n",
    "from nengo.utils.filter_design import cont2discrete\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.callbacks import Callback\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.utils import to_categorical\n",
    "from keras.regularizers import l2,l1\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2_as_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "urban-awareness",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMUCell(nengo.Network):\n",
    "    def __init__(self, units, order, theta, input_d, tau, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        Q = np.arange(order, dtype=np.float64)\n",
    "        R = (2 * Q + 1)[:, None] / theta\n",
    "        j, i = np.meshgrid(Q, Q)\n",
    "\n",
    "        A = np.where(i < j, -1, (-1.0) ** (i - j + 1)) * R \n",
    "        B = (-1.0) ** Q[:, None] * R \n",
    "        C = np.ones((1, order))\n",
    "        D = np.zeros((1,))\n",
    "\n",
    "        A, B, _, _, _ = cont2discrete((A, B, C, D), dt=tau, method=\"zoh\") # original: dt=1.0\n",
    "\n",
    "        A_H = 1/(1-np.exp(-1/tau)) * (A - np.exp(-1/tau)*np.identity(order))\n",
    "        B_H = 1/(1-np.exp(-1/tau)) * B\n",
    "\n",
    "\n",
    "        with self:\n",
    "            nengo_dl.configure_settings(trainable=None)\n",
    "\n",
    "            # create objects corresponding to the x/u/m/h\n",
    "            self.x = nengo.Node(size_in=input_d)\n",
    "            self.u = nengo.Node(size_in=1)\n",
    "            self.m = nengo.Node(size_in=order)\n",
    "            self.h = nengo_dl.TensorNode(tf.nn.tanh, shape_in=(units,), pass_time=False)\n",
    "\n",
    "            # compute u_t:\n",
    "            # e_x\n",
    "            nengo.Connection(\n",
    "                self.x, self.u, transform=np.ones((1, input_d)), synapse=None\n",
    "            )\n",
    "            \n",
    "            # e_h\n",
    "            nengo.Connection(\n",
    "                self.h, self.u, transform=np.ones((1, units)), synapse=0\n",
    "            )\n",
    "            \n",
    "            # e_m\n",
    "            nengo.Connection(\n",
    "                self.m, self.u, transform=np.ones((1, order)), synapse=0\n",
    "            )\n",
    "\n",
    "            # compute m_t:\n",
    "            conn_A = nengo.Connection(self.m, self.m, transform=A_H, synapse=0)\n",
    "            self.config[conn_A].trainable = True\n",
    "            conn_B = nengo.Connection(self.u, self.m, transform=B_H, synapse=None)\n",
    "            self.config[conn_B].trainable = True\n",
    "\n",
    "            # compute h_t:\n",
    "            nengo.Connection(\n",
    "                self.x, self.h, transform=nengo_dl.dists.Glorot(), synapse=None\n",
    "            )\n",
    "            nengo.Connection(\n",
    "                self.h, self.h, transform=nengo_dl.dists.Glorot(), synapse=0\n",
    "            )\n",
    "            nengo.Connection(\n",
    "                self.m, self.h, transform=nengo_dl.dists.Glorot(), synapse=None,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "technological-folks",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wisdm2_data(filename):\n",
    "    filepath = os.path.join('./data/',filename+'.npz')\n",
    "    a = np.load(filepath)\n",
    "    return (a['arr_0'], a['arr_1'], a['arr_2'], a['arr_3'], a['arr_4'], a['arr_5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "experienced-modeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceData:\n",
    "    def __init__(self, sample, fs, channels):\n",
    "        self.data = []\n",
    "        sample = sample.T\n",
    "        for data_axis in range(sample.shape[0]):\n",
    "            self.data.append(sample[data_axis, :])\n",
    "\n",
    "        self.fs = fs\n",
    "        self.freq_range = (0.5, np.floor(self.fs / 2))\n",
    "\n",
    "        freq_min, freq_max = self.freq_range\n",
    "        octave = (channels - 0.5) * np.log10(2) / np.log10(freq_max / freq_min)\n",
    "        self.freq_centr = np.array([freq_min * (2 ** (ch / octave)) for ch in range(channels)])\n",
    "        self.freq_poli = np.array(\n",
    "            [(freq * (2 ** (-1 / (2 * octave))), (freq * (2 ** (1 / (2 * octave))))) for freq in self.freq_centr])\n",
    "        self.freq_poli[-1, 1] = fs / 2 * 0.99999\n",
    "\n",
    "    def decomposition(self, filterbank):\n",
    "        self.components = []\n",
    "        for data_axis in self.data:\n",
    "            tmp = []\n",
    "            for num, den in filterbank:\n",
    "                from scipy.signal import lfilter\n",
    "                tmp.append(lfilter(num, den, data_axis))\n",
    "            self.components.append(tmp)\n",
    "\n",
    "\n",
    "def frequency_decomposition(array, channels=5, fs=20, order=2):\n",
    "\n",
    "    array_dec = []\n",
    "\n",
    "    for ii in range(len(array)):\n",
    "    \n",
    "        sample = DeviceData(array[ii], fs, channels)\n",
    "    \n",
    "        butter_filterbank = []\n",
    "        for fl, fh in sample.freq_poli:\n",
    "            num, den = butter(N=order, Wn=(fl, fh), btype='band', fs=sample.fs)\n",
    "            butter_filterbank.append([num, den])\n",
    "    \n",
    "        sample.decomposition(butter_filterbank)\n",
    "    \n",
    "        features = []\n",
    "        for data_axis in sample.components:\n",
    "            for component in data_axis:\n",
    "                features.append(np.array(component))\n",
    "        features = np.vstack(features)\n",
    "        features = features.T\n",
    "    \n",
    "        array_dec.append(features)\n",
    "\n",
    "    return np.array(array_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "flexible-hormone",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss and accuracy at the end of training\n",
    "def plot_graphs(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.plot(history.history['val_'+string])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.legend(['train_'+string, 'val_'+string])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "civilian-sheep",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConfusionMatrix_labels(subset):\n",
    "    \n",
    "    act_map = {\n",
    "        'A': 'walking',\n",
    "        'B': 'jogging',\n",
    "        'C': 'stairs',\n",
    "        'D': 'sitting',\n",
    "        'E': 'standing',\n",
    "        'M': 'kicking',\n",
    "        'P': 'dribbling',\n",
    "        'O': 'catch',\n",
    "        'F': 'typing',\n",
    "        'Q': 'writing',\n",
    "        'R': 'clapping',\n",
    "        'G': 'teeth',\n",
    "        'S': 'folding',\n",
    "        'J': 'pasta',\n",
    "        'H': 'soup',\n",
    "        'L': 'sandwich',\n",
    "        'I': 'chips',\n",
    "        'K': 'drinking',\n",
    "    }\n",
    "    \n",
    "    if subset == 1:\n",
    "        labels = list(act_map.values())[:6]\n",
    "    if subset == 2:\n",
    "        labels = list(act_map.values())[6:13]\n",
    "    if subset == 3:\n",
    "        labels = list(act_map.values())[13:]\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "documentary-armor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def memory_footprint(model, nengo=True):\n",
    "    \n",
    "    mem_fp = 0\n",
    "    total = 0\n",
    "    missed = 0\n",
    "    \n",
    "    if nengo:\n",
    "        \n",
    "        model_weights = model.keras_model.weights\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        model_weights = model.weights\n",
    "        \n",
    "    for s in model_weights:\n",
    "        if ('32' in str(s.dtype)) or (str(s.dtype)=='int'):\n",
    "            mem = 4*np.prod(s.shape)/1e6 # MB\n",
    "            total += np.prod(s.shape)\n",
    "            mem_fp += mem\n",
    "        elif '64' in str(s.dtype):\n",
    "            mem = 8*np.prod(s.shape)/1e6 # MB\n",
    "            total += np.prod(s.shape)\n",
    "            mem_fp += mem\n",
    "        else:\n",
    "            missed += np.prod(s.shape)\n",
    "    \n",
    "    return mem_fp, total, missed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "english-colorado",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flops(model):\n",
    "    \n",
    "    concrete = tf.function(lambda inputs: model(inputs))\n",
    "    concrete_func = concrete.get_concrete_function([tf.TensorSpec([1, *inputs.shape[1:]]) for inputs in model.inputs])\n",
    "    \n",
    "    frozen_func, graph_def = convert_variables_to_constants_v2_as_graph(concrete_func)\n",
    "    \n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.graph_util.import_graph_def(graph_def, name='')\n",
    "        run_meta = tf.compat.v1.RunMetadata()\n",
    "        opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
    "        flops = tf.compat.v1.profiler.profile(graph=graph, run_meta=run_meta, cmd=\"op\", options=opts)\n",
    "        \n",
    "        return flops.total_float_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aquatic-field",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sops_LMUens(net, freqdec=False):\n",
    "    \n",
    "    with net:\n",
    "        lmu_inner.add_neuron_output()\n",
    "        p_spikes = nengo.Probe(lmu_inner.neuron_output, label=\"p_spikes\")\n",
    "        net.config[p_spikes].keep_history = True\n",
    "    \n",
    "    with nengo_dl.Simulator(net) as sim:\n",
    "        \n",
    "        sim.load_params(\"./output/tmp_{}_{}_{}/best_test_{}\".format(net_type,optim_nni_experiment,datafile[5:],optim_nni_experiment))\n",
    "    \n",
    "        sops = []\n",
    "        accs = []\n",
    "        \n",
    "        dt = 0.001 # the default value in Nengo\n",
    "    \n",
    "        for ii in range(int(0.1*len(x_test))):\n",
    "            \n",
    "            simulation_steps = int(len(x_test[ii]))\n",
    "    \n",
    "            sim.run_steps(simulation_steps, data={inp: x_test[ii][np.newaxis,:,:]})\n",
    "    \n",
    "        spikes = sim.data[p_spikes]/amplitude*dt\n",
    "        spikes_per_neuron = np.sum(spikes > 0, axis=0)\n",
    "        sops = np.sum(spikes_per_neuron)/int(0.1*len(x_test))\n",
    "    \n",
    "        energy = sops*5.07e-10 # Event-Driven Signal Processing with Neuromorphic Computing Systems, https://ieeexplore.ieee.org/document/9053043/\n",
    "    \n",
    "        num_nn = 0\n",
    "        for ee in net.all_ensembles:\n",
    "            for nn in ee.neurons:\n",
    "                num_nn +=1\n",
    "        \n",
    "        print(\"\\n\")\n",
    "        print(\"Total number of neurons:\",int(num_nn))\n",
    "        print(\"SOPs:\",int(np.round(np.mean(sops),0)))\n",
    "        print(\"Energy evaluation on Loihi: \"+str(np.round(energy*1e6,2))+\" μJ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "controversial-mainstream",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bonito=np.random.rand(1,4,2000)*255\n",
    "def get_sops_spikingCNN(net):\n",
    "    \n",
    "    with net:\n",
    "        \n",
    "        dense_p = nengo.Probe(net.layers[model.layers[5].get_output_at(-1)])\n",
    "    \n",
    "    with nengo_dl.Simulator(net) as sim:\n",
    "        \n",
    "        #sim.load_params(\"./output/tmp_s{}_{}_{}/best_test_{}\".format(net_type,snn_nni_experiment,datafile[5:],snn_nni_experiment))\n",
    "    \n",
    "        sops = []\n",
    "        preds = []\n",
    "        accs = []\n",
    "        \n",
    "        dt = 0.001 # the default value in Nengo\n",
    "    \n",
    "        for ii in range(int(0.1*len(x_bonito))): #tiled_x_test\n",
    "            \n",
    "            simulation_steps = int(len(x_test[ii])) #tiled_x_test\n",
    "        \n",
    "            sim.run_steps(simulation_steps, data={net.all_nodes[0]: x_bonito[ii][np.newaxis,:,:]}) #tiled_x_test\n",
    "    \n",
    "        spikes_conv0 = sim.data[conv0_p]/(1/100)*dt #snn_parameters['nni_keras2snn_network/scale_firing_rates/randint']\n",
    "        spikes_conv1 = sim.data[conv1_p]/(1/100)*dt\n",
    "        spikes_dense = sim.data[dense_p]/(1/100)*dt\n",
    "        spikes_per_neuron_conv0 = np.sum(spikes_conv0 > 0, axis=0)\n",
    "        spikes_per_neuron_conv1 = np.sum(spikes_conv1 > 0, axis=0)\n",
    "        spikes_per_neuron_dense = np.sum(spikes_dense > 0, axis=0)\n",
    "        sops = np.sum([np.sum(spikes_per_neuron_conv0), np.sum(spikes_per_neuron_conv1), np.sum(spikes_per_neuron_dense)]) / int(0.1*len(x_bonito)) #tiled_x_test\n",
    "    \n",
    "        energy = sops*5.07e-10 # Event-Driven Signal Processing with Neuromorphic Computing Systems, https://ieeexplore.ieee.org/document/9053043/\n",
    "        \n",
    "        num_nn = 0\n",
    "        for ee in net.all_ensembles:\n",
    "            for nn in ee.neurons:\n",
    "                num_nn +=1\n",
    "        \n",
    "        print(\"\\n\")\n",
    "        print(\"Total number of neurons:\",int(num_nn))\n",
    "        print(\"SOPs:\",int(np.round(np.mean(sops),0)))\n",
    "        print(\"Energy evaluation on Loihi: \"+str(np.round(energy*1e6,2))+\" μJ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interested-occurrence",
   "metadata": {},
   "source": [
    "<a id='Section_1'></a>\n",
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "magnetic-mortality",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# set seed to ensure the examples are reproducible\n",
    "seed = 0\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "surgical-sewing",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_type = 'lstm'\n",
    "\n",
    "device = 'watch'\n",
    "subset = 2\n",
    "time_window = 2\n",
    "\n",
    "window_size = 20*time_window # 20 Hz sampling times the temporal length of the window\n",
    "\n",
    "datafile = 'data_'+device+'_subset'+str(subset)+'_'+str(window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "authorized-elimination",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"LSTM_{}_subset{}_{}\".format(device,subset,window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "theoretical-amino",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### GET NETWORK STRUCTURE PARAMETERS #####\n",
    "optim_nni_experiment = ''\n",
    "optim_nni_trial = ''\n",
    "optim_filename = 'parameter.cfg'\n",
    "optim_nni_ref = 'nni-experiments/'+optim_nni_experiment+'/trials/'+optim_nni_trial\n",
    "optim_nni_dir = os.path.expanduser('~')\n",
    "optim_filepath = os.path.join(optim_nni_dir,optim_nni_ref,optim_filename)\n",
    "\n",
    "with open(\"./fakeparams.cfg\", 'r') as f:\n",
    "    data = f.read()\n",
    "\n",
    "params = json.loads(data)\n",
    "network_parameters = params['parameters']\n",
    "\n",
    "minibatch_train = network_parameters['nni_network/batch_size/randint']\n",
    "###########################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b826687",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dress-provision",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timesteps: 40\n",
      "input_dim: 6\n",
      "n_classes: 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7241"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train, x_val, x_test, y_train_oh, y_val_oh, y_test_oh) = load_wisdm2_data(datafile)\n",
    "timesteps = len(x_train[0])\n",
    "input_dim = len(x_train[0][0])\n",
    "n_classes = len(y_train_oh[0])\n",
    "\n",
    "y_train = y_train_oh\n",
    "y_val = y_val_oh\n",
    "y_test = y_test_oh\n",
    "\n",
    "print('timesteps:',timesteps)\n",
    "print('input_dim:',input_dim)\n",
    "print('n_classes:',n_classes)\n",
    "x_test.shape\n",
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "modern-holiday",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-16 11:50:52.264515: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 40, 128)           69120     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 40, 128)           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 7)                 903       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 201,607\n",
      "Trainable params: 201,607\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/base_arch2/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# First LSTM layer\n",
    "model.add(LSTM(network_parameters['nni_network/LSTM_units_1/randint'],\n",
    "               return_sequences=True,\n",
    "               input_shape=(timesteps, input_dim))\n",
    "        )\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(network_parameters['nni_network/LSTM_Dropout_1/quniform']))\n",
    "# Second LSTM layer\n",
    "model.add(LSTM(network_parameters['nni_network/LSTM_units_2/randint'],\n",
    "               recurrent_regularizer=l2(network_parameters['nni_network/LSTM_l2_2/quniform']), \n",
    "               input_shape=(timesteps, input_dim))\n",
    "         ) \n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(network_parameters['nni_network/LSTM_Dropout_2/quniform']))\n",
    "# Adding a dense output layer\n",
    "model.add(Dense(n_classes, activation='softmax')) \n",
    "model.summary()\n",
    "\n",
    "# Compiling the model\n",
    "optim = Adam(lr=network_parameters['nni_network/lr/quniform'])\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optim,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79510298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_3 (Conv1D)           (1, 2000, 4)              24        \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (1, 2000, 16)             336       \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (1, 400, 384)             117120    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 117,480\n",
      "Trainable params: 117,480\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "\n",
    "#inp = tf.keras.Input(shape=( 1, 2000)) #4, 2000\n",
    "\n",
    "conv0 = tf.keras.layers.Conv1D(\n",
    "    filters=4,\n",
    "    kernel_size=5,\n",
    "    strides=1,\n",
    "    padding=\"same\",\n",
    "    activation=tf.nn.silu,\n",
    ")\n",
    "model.add(conv0)\n",
    "\n",
    "conv1 = tf.keras.layers.Conv1D(\n",
    "    filters=16,\n",
    "    kernel_size=5,\n",
    "    strides=1,\n",
    "    padding=\"same\",\n",
    "    activation=tf.nn.silu,\n",
    ")\n",
    "model.add(conv1)\n",
    "\n",
    "conv2 = tf.keras.layers.Conv1D(\n",
    "    filters=384,\n",
    "    kernel_size=19,\n",
    "    strides=5,\n",
    "    padding=\"same\",\n",
    "    activation=tf.nn.silu,\n",
    ")\n",
    "model.add(conv2)\n",
    "\"\"\"\n",
    "for i in range(5):\n",
    "    model.add(LSTM(384,input_shape=(4,400,384), return_sequences=True))\n",
    "    pass\n",
    "\"\"\"\n",
    "#k_model2 = tf.keras.Model(inputs=inp, outputs=conv2)\n",
    "optim = Adam(lr=network_parameters['nni_network/lr/quniform'])\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optim,\n",
    "              metrics=['accuracy'])\n",
    "model.build(( 1,2000,1))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "destroyed-slope",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory footprint (MB): 0.4699\n",
      "Total: 117480\n",
      "Missed: 0\n"
     ]
    }
   ],
   "source": [
    "mem_fp, total, missed = memory_footprint(model, nengo=False)\n",
    "\n",
    "print('Memory footprint (MB):',np.round(mem_fp,4))\n",
    "print('Total:',total)\n",
    "print('Missed:',missed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "boolean-trance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=[<tf.Tensor 'inputs:0' shape=(1, 2000, 1) dtype=float32>]. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/miniconda3/envs/base_arch2/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py:5250: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "op: The nodes are operation kernel type, such as MatMul, Conv2D. Graph nodes belonging to the same type are aggregated together.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "Conv2D                   94.75m float_ops (100.00%, 99.39%)\n",
      "Mul                      387.20k float_ops (0.61%, 0.41%)\n",
      "BiasAdd                  193.60k float_ops (0.20%, 0.20%)\n",
      "\n",
      "======================End of Report==========================\n",
      "FLOPs: 95329600\n"
     ]
    }
   ],
   "source": [
    "print(\"FLOPs: {}\".format(get_flops(model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "senior-stock",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=[<tf.Tensor 'inputs:0' shape=(1, 2000, 1) dtype=float32>]. Consider rewriting this model with the Functional API.\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "Energy evaluation on Movidius: 71783.19 μJ\n",
      "\n",
      "Doc:\n",
      "op: The nodes are operation kernel type, such as MatMul, Conv2D. Graph nodes belonging to the same type are aggregated together.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "Conv2D                   94.75m float_ops (100.00%, 99.39%)\n",
      "Mul                      387.20k float_ops (0.61%, 0.41%)\n",
      "BiasAdd                  193.60k float_ops (0.20%, 0.20%)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    }
   ],
   "source": [
    "energy = get_flops(model)*7.53e-10 # Event-Driven Signal Processing with Neuromorphic Computing Systems, https://ieeexplore.ieee.org/document/9053043/\n",
    "\n",
    "print(\"Energy evaluation on Movidius: \"+str(np.round(energy*1e6,2))+\" μJ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "worldwide-parker",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ./output/tmp_lstm__watch_subset2_40/best_test/best_test_",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/utente/Desktop/MLA/progetto/NeHAR/post-optimization.ipynb Cell 27\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/utente/Desktop/MLA/progetto/NeHAR/post-optimization.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mload_weights(\u001b[39m\"\u001b[39;49m\u001b[39m./output/tmp_\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m/best_test/best_test_\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mformat(net_type,optim_nni_experiment,datafile[\u001b[39m5\u001b[39;49m:],optim_nni_experiment))\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/utente/Desktop/MLA/progetto/NeHAR/post-optimization.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m _, acc \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(x_test, y_test, batch_size\u001b[39m=\u001b[39mminibatch_train)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/utente/Desktop/MLA/progetto/NeHAR/post-optimization.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTest accuracy: \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(np\u001b[39m.\u001b[39mround(acc\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m,\u001b[39m2\u001b[39m))\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/base_arch2/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/base_arch2/lib/python3.8/site-packages/tensorflow/python/training/py_checkpoint_reader.py:31\u001b[0m, in \u001b[0;36merror_translator\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m     27\u001b[0m error_message \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(e)\n\u001b[1;32m     28\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mnot found in checkpoint\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m error_message \u001b[39mor\u001b[39;00m (\n\u001b[1;32m     29\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mFailed to find any \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     30\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmatching files for\u001b[39m\u001b[39m'\u001b[39m) \u001b[39min\u001b[39;00m error_message:\n\u001b[0;32m---> 31\u001b[0m   \u001b[39mraise\u001b[39;00m errors_impl\u001b[39m.\u001b[39mNotFoundError(\u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, error_message)\n\u001b[1;32m     32\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mSliced checkpoints are not supported\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m error_message \u001b[39mor\u001b[39;00m (\n\u001b[1;32m     33\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mData type \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     34\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mnot \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     35\u001b[0m     \u001b[39m'\u001b[39m\u001b[39msupported\u001b[39m\u001b[39m'\u001b[39m) \u001b[39min\u001b[39;00m error_message:\n\u001b[1;32m     36\u001b[0m   \u001b[39mraise\u001b[39;00m errors_impl\u001b[39m.\u001b[39mUnimplementedError(\u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, error_message)\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ./output/tmp_lstm__watch_subset2_40/best_test/best_test_"
     ]
    }
   ],
   "source": [
    "model.load_weights(\"./output/tmp_{}_{}_{}/best_test/best_test_{}\".format(net_type,optim_nni_experiment,datafile[5:],optim_nni_experiment))\n",
    "\n",
    "_, acc = model.evaluate(x_test, y_test, batch_size=minibatch_train)\n",
    "print(\"Test accuracy: \"+str(np.round(acc*100,2))+\"%\")\n",
    "\n",
    "pred = model.predict(x_test, batch_size=minibatch_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "equivalent-montgomery",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/utente/Desktop/MLA/progetto/NeHAR/post-optimization.ipynb Cell 28\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/utente/Desktop/MLA/progetto/NeHAR/post-optimization.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m save \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/utente/Desktop/MLA/progetto/NeHAR/post-optimization.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m cm \u001b[39m=\u001b[39m confusion_matrix(y_test\u001b[39m.\u001b[39margmax(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), pred\u001b[39m.\u001b[39margmax(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), normalize\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrue\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/utente/Desktop/MLA/progetto/NeHAR/post-optimization.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m labels \u001b[39m=\u001b[39m ConfusionMatrix_labels(subset)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/utente/Desktop/MLA/progetto/NeHAR/post-optimization.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m cm_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(cm, index\u001b[39m=\u001b[39m[ii \u001b[39mfor\u001b[39;00m ii \u001b[39min\u001b[39;00m labels], columns\u001b[39m=\u001b[39m[jj \u001b[39mfor\u001b[39;00m jj \u001b[39min\u001b[39;00m labels])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred' is not defined"
     ]
    }
   ],
   "source": [
    "save = False\n",
    "\n",
    "cm = confusion_matrix(y_test.argmax(axis=1), pred.argmax(axis=1), normalize='true')\n",
    "labels = ConfusionMatrix_labels(subset)\n",
    "cm_df = pd.DataFrame(cm, index=[ii for ii in labels], columns=[jj for jj in labels])\n",
    "plt.figure(figsize=(7,5.25))\n",
    "sn.heatmap(cm_df,\n",
    "           annot=True,\n",
    "           fmt='.2g',\n",
    "           cbar=False,\n",
    "           square=False,\n",
    "           cmap=\"YlGnBu\")\n",
    "plt.xlabel('\\nPredicted')\n",
    "plt.ylabel('True\\n')\n",
    "plt.yticks(rotation=0)\n",
    "plt.title('LSTM\\n', fontweight='bold', fontsize=16)\n",
    "plt.tight_layout()\n",
    "if save:\n",
    "    plt.savefig('./pictures/'+model_name+'_'+optim_nni_experiment+'_'+optim_nni_trial+'.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "violent-international",
   "metadata": {},
   "source": [
    "<a id='Section_2'></a>\n",
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-communist",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# set seed to ensure the examples are reproducible\n",
    "seed = 0\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funded-builder",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_type = 'cnn'\n",
    "\n",
    "device = 'watch'\n",
    "subset = 2\n",
    "time_window = 2\n",
    "\n",
    "window_size = 20*time_window # 20 Hz sampling times the temporal length of the window\n",
    "\n",
    "datafile = 'data_'+device+'_subset'+str(subset)+'_'+str(window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-study",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"CNN_{}_subset{}_{}\".format(device,subset,window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-shell",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### GET NETWORK STRUCTURE PARAMETERS #####\n",
    "optim_nni_experiment = ''\n",
    "optim_nni_trial = ''\n",
    "optim_filename = 'parameter.cfg'\n",
    "optim_nni_ref = 'nni-experiments/'+optim_nni_experiment+'/trials/'+optim_nni_trial\n",
    "optim_nni_dir = os.path.expanduser('~')\n",
    "optim_filepath = os.path.join(optim_nni_dir,optim_nni_ref,optim_filename)\n",
    "\n",
    "with open(optim_filepath, 'r') as f:\n",
    "    data = f.read()\n",
    "\n",
    "params = json.loads(data)\n",
    "network_parameters = params['parameters']\n",
    "\n",
    "minibatch_train = network_parameters['nni_network/batch_size/randint']\n",
    "###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-drinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, x_val, x_test, y_train_oh, y_val_oh, y_test_oh) = load_wisdm2_data(datafile)\n",
    "timesteps = len(x_train[0])\n",
    "input_dim = len(x_train[0][0])\n",
    "n_classes = len(y_train_oh[0])\n",
    "\n",
    "y_train = y_train_oh\n",
    "y_val = y_val_oh\n",
    "y_test = y_test_oh\n",
    "\n",
    "print('timesteps:',timesteps)\n",
    "print('input_dim:',input_dim)\n",
    "print('n_classes:',n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-collect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# First convolutional layer\n",
    "model.add(Conv1D(filters=network_parameters['nni_network/Conv1D_filters_1/randint'], \n",
    "                 kernel_size=network_parameters['nni_network/Conv1D_kernel_size_1/randint'], \n",
    "                 activation='relu',\n",
    "                 kernel_initializer='he_uniform',\n",
    "                 input_shape=(timesteps,input_dim))\n",
    "         )\n",
    "# Second convolutional layer\n",
    "model.add(Conv1D(filters=network_parameters['nni_network/Conv1D_filters_2/randint'], \n",
    "                 kernel_size=network_parameters['nni_network/Conv1D_kernel_size_2/randint'], \n",
    "                 activation='relu',\n",
    "                 kernel_initializer='he_uniform')\n",
    "         )\n",
    "# Adding a pooling layer\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "# Adding a flattening layer\n",
    "model.add(Flatten())\n",
    "# Adding a dense layer\n",
    "model.add(Dense(network_parameters['nni_network/CNN_Dense_1/randint'], \n",
    "                activation='relu')\n",
    "         )\n",
    "# Adding a dense output layer\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "# Compiling the model\n",
    "optim = Adam(lr=network_parameters['nni_network/lr/quniform'])\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optim,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-chess",
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_fp, total, missed = memory_footprint(model, nengo=False)\n",
    "\n",
    "print('Memory footprint (MB):',np.round(mem_fp,4))\n",
    "print('Total:',total)\n",
    "print('Missed:',missed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peripheral-designer",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"FLOPs: {}\".format(get_flops(model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-premiere",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy = get_flops(model)*7.53e-10 # Event-Driven Signal Processing with Neuromorphic Computing Systems, https://ieeexplore.ieee.org/document/9053043/\n",
    "\n",
    "print(\"Energy evaluation on Movidius: \"+str(np.round(energy*1e6,2))+\" μJ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-outside",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"./output/tmp_{}_{}_{}/best_test/best_test_{}\".format(net_type,optim_nni_experiment,datafile[5:],optim_nni_experiment))\n",
    "\n",
    "_, acc = model.evaluate(x_test, y_test, batch_size=minibatch_train)\n",
    "print(\"Test accuracy: \"+str(np.round(acc*100,2))+\"%\")\n",
    "\n",
    "pred = model.predict(x_test, batch_size=minibatch_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-vacuum",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = False\n",
    "\n",
    "cm = confusion_matrix(y_test.argmax(axis=1), pred.argmax(axis=1), normalize='true')\n",
    "labels = ConfusionMatrix_labels(subset)\n",
    "cm_df = pd.DataFrame(cm, index=[ii for ii in labels], columns=[jj for jj in labels])\n",
    "plt.figure(figsize=(7,5.25))\n",
    "sn.heatmap(cm_df,\n",
    "           annot=True,\n",
    "           fmt='.2g',\n",
    "           cbar=False,\n",
    "           square=False,\n",
    "           cmap=\"YlGnBu\")\n",
    "plt.xlabel('\\nPredicted')\n",
    "plt.ylabel('True\\n')\n",
    "plt.yticks(rotation=0)\n",
    "plt.title('CNN\\n', fontweight='bold', fontsize=16)\n",
    "plt.tight_layout()\n",
    "if save:\n",
    "    plt.savefig('./pictures/'+model_name+'_'+optim_nni_experiment+'_'+optim_nni_trial+'.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "printable-thomson",
   "metadata": {},
   "source": [
    "<a id='Section_3'></a>\n",
    "### Spiking CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "emerging-texture",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# set seed to ensure the examples are reproducible\n",
    "seed = 0\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "unexpected-affair",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_type = 'cnn'\n",
    "\n",
    "device = 'watch'\n",
    "subset = 2\n",
    "time_window = 2\n",
    "\n",
    "window_size = 20*time_window # 20 Hz sampling times the temporal length of the window\n",
    "\n",
    "datafile = 'data_'+device+'_subset'+str(subset)+'_'+str(window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "provincial-thanks",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"sCNN_{}_subset{}_{}\".format(device,subset,window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "republican-meter",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/root/nni-experiments//trials/parameter.cfg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/utente/Desktop/MLA/progetto/NeHAR/post-optimization.ipynb Cell 46\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/utente/Desktop/MLA/progetto/NeHAR/post-optimization.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m optim_nni_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexpanduser(\u001b[39m'\u001b[39m\u001b[39m~\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/utente/Desktop/MLA/progetto/NeHAR/post-optimization.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m optim_filepath \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(optim_nni_dir,optim_nni_ref,optim_filename)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/utente/Desktop/MLA/progetto/NeHAR/post-optimization.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(optim_filepath, \u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/utente/Desktop/MLA/progetto/NeHAR/post-optimization.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     data \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mread()\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/utente/Desktop/MLA/progetto/NeHAR/post-optimization.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m params \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mloads(data)\n",
      "File \u001b[0;32m~/miniconda3/envs/base_arch2/lib/python3.8/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/root/nni-experiments//trials/parameter.cfg'"
     ]
    }
   ],
   "source": [
    "##### GET NETWORK STRUCTURE PARAMETERS from NNI-optimized non-spiking CNN #####\n",
    "optim_nni_experiment = ''\n",
    "optim_nni_trial = ''\n",
    "optim_filename = 'parameter.cfg'\n",
    "optim_nni_ref = 'nni-experiments/'+optim_nni_experiment+'/trials/'+optim_nni_trial\n",
    "optim_nni_dir = os.path.expanduser('~')\n",
    "optim_filepath = os.path.join(optim_nni_dir,optim_nni_ref,optim_filename)\n",
    "\n",
    "with open(optim_filepath, 'r') as f:\n",
    "    data = f.read()\n",
    "\n",
    "params = json.loads(data)\n",
    "network_parameters = params['parameters']\n",
    "\n",
    "minibatch_train = network_parameters['nni_network/batch_size/randint']\n",
    "##############################################################################\n",
    "\n",
    "\n",
    "##### GET SNN PARAMETERS #####\n",
    "snn_nni_experiment = ''\n",
    "snn_nni_trial = '' \n",
    "snn_filename = 'parameter.cfg'\n",
    "snn_nni_ref = 'nni-experiments/'+snn_nni_experiment+'/trials/'+snn_nni_trial\n",
    "snn_nni_dir = os.path.expanduser('~')\n",
    "snn_filepath = os.path.join(snn_nni_dir,snn_nni_ref,snn_filename)\n",
    "\n",
    "with open(snn_filepath, 'r') as f:\n",
    "    snn_data = f.read()\n",
    "\n",
    "snn_params = json.loads(snn_data)\n",
    "snn_parameters = snn_params['parameters']\n",
    "##############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dominican-priest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timesteps: 40\n",
      "input_dim: 6\n",
      "n_classes: 7\n"
     ]
    }
   ],
   "source": [
    "(x_train, x_val, x_test, y_train_oh, y_val_oh, y_test_oh) = load_wisdm2_data(datafile)\n",
    "timesteps = len(x_train[0])\n",
    "input_dim = len(x_train[0][0])\n",
    "n_classes = len(y_train_oh[0])\n",
    "\n",
    "y_train = np.argmax(y_train_oh, axis=-1)\n",
    "y_val = np.argmax(y_val_oh, axis=-1)\n",
    "y_test = np.argmax(y_test_oh, axis=-1)\n",
    "\n",
    "print('timesteps:',timesteps)\n",
    "print('input_dim:',input_dim)\n",
    "print('n_classes:',n_classes)\n",
    "\n",
    "### flatten data and add time dimension:\n",
    "x_train = x_train.reshape((x_train.shape[0], 1, -1))\n",
    "y_train = y_train[:,None,None]\n",
    "x_val = x_val.reshape((x_val.shape[0], 1, -1))\n",
    "y_val = y_val[:,None,None]\n",
    "x_test = x_test.reshape((x_test.shape[0], 1, -1))\n",
    "y_test = y_test[:,None,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "expensive-latino",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'nni_network/Conv1D_filters_1/randint'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/utente/Desktop/MLA/progetto/NeHAR/post-optimization.ipynb Cell 47\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/utente/Desktop/MLA/progetto/NeHAR/post-optimization.ipynb#X63sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model_nonspiking \u001b[39m=\u001b[39m Sequential()    \n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/utente/Desktop/MLA/progetto/NeHAR/post-optimization.ipynb#X63sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m model_nonspiking\u001b[39m.\u001b[39madd(Conv1D(filters\u001b[39m=\u001b[39mnetwork_parameters[\u001b[39m'\u001b[39;49m\u001b[39mnni_network/Conv1D_filters_1/randint\u001b[39;49m\u001b[39m'\u001b[39;49m], kernel_size\u001b[39m=\u001b[39mnetwork_parameters[\u001b[39m'\u001b[39m\u001b[39mnni_network/Conv1D_kernel_size_1/randint\u001b[39m\u001b[39m'\u001b[39m], activation\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mrelu, kernel_initializer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhe_uniform\u001b[39m\u001b[39m'\u001b[39m, input_shape\u001b[39m=\u001b[39m(timesteps,input_dim), name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mConv1D_1\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/utente/Desktop/MLA/progetto/NeHAR/post-optimization.ipynb#X63sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m model_nonspiking\u001b[39m.\u001b[39madd(Conv1D(filters\u001b[39m=\u001b[39mnetwork_parameters[\u001b[39m'\u001b[39m\u001b[39mnni_network/Conv1D_filters_2/randint\u001b[39m\u001b[39m'\u001b[39m], kernel_size\u001b[39m=\u001b[39mnetwork_parameters[\u001b[39m'\u001b[39m\u001b[39mnni_network/Conv1D_kernel_size_2/randint\u001b[39m\u001b[39m'\u001b[39m], activation\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mrelu, kernel_initializer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhe_uniform\u001b[39m\u001b[39m'\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mConv1D_2\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/utente/Desktop/MLA/progetto/NeHAR/post-optimization.ipynb#X63sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m model_nonspiking\u001b[39m.\u001b[39madd(MaxPooling1D(pool_size\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mMaxPooling1D\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'nni_network/Conv1D_filters_1/randint'"
     ]
    }
   ],
   "source": [
    "model_nonspiking = Sequential()    \n",
    "model_nonspiking.add(Conv1D(filters=network_parameters['nni_network/Conv1D_filters_1/randint'], kernel_size=network_parameters['nni_network/Conv1D_kernel_size_1/randint'], activation=tf.nn.relu, kernel_initializer='he_uniform', input_shape=(timesteps,input_dim), name='Conv1D_1'))\n",
    "model_nonspiking.add(Conv1D(filters=network_parameters['nni_network/Conv1D_filters_2/randint'], kernel_size=network_parameters['nni_network/Conv1D_kernel_size_2/randint'], activation=tf.nn.relu, kernel_initializer='he_uniform', name='Conv1D_2'))\n",
    "model_nonspiking.add(MaxPooling1D(pool_size=2, name='MaxPooling1D'))\n",
    "model_nonspiking.add(Flatten())\n",
    "model_nonspiking.add(Dense(network_parameters['nni_network/CNN_Dense_1/randint'], activation=tf.nn.relu, name='Dense_1'))\n",
    "model_nonspiking.add(Dense(n_classes, activation='softmax', name='Dense_2'))\n",
    "    \n",
    "### LOAD PRE-TRAINED WEIGHTS from NNI-optimized non-spiking CNN ###\n",
    "model_nonspiking.load_weights(\"./output/tmp_cnn_{}_{}/best_test/best_test_{}\".format(net_type,optim_nni_experiment,datafile[5:],optim_nni_experiment))\n",
    "\n",
    "### sequential to functional model\n",
    "input_layer = Input(batch_shape=model_nonspiking.layers[0].input_shape, name='Input')\n",
    "prev_layer = input_layer\n",
    "for num,el in enumerate(model_nonspiking.layers):\n",
    "    prev_layer = el(prev_layer)\n",
    "\n",
    "model = Model([input_layer], [prev_layer])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "comfortable-cleaner",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_layers = list(model.layers[ii].name for ii in range(len(model.layers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "smaller-knowing",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'snn_parameters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/utente/Desktop/MLA/progetto/NeHAR/post-optimization.ipynb Cell 49\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/utente/Desktop/MLA/progetto/NeHAR/post-optimization.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m trained_converter \u001b[39m=\u001b[39m nengo_dl\u001b[39m.\u001b[39mConverter(model,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/utente/Desktop/MLA/progetto/NeHAR/post-optimization.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m                                        max_to_avg_pool\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/utente/Desktop/MLA/progetto/NeHAR/post-optimization.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m                                        swap_activations\u001b[39m=\u001b[39m{tf\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mrelu: nengo\u001b[39m.\u001b[39mSpikingRectifiedLinear()},\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/utente/Desktop/MLA/progetto/NeHAR/post-optimization.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m                                        scale_firing_rates\u001b[39m=\u001b[39msnn_parameters[\u001b[39m'\u001b[39m\u001b[39mnni_keras2snn_network/scale_firing_rates/randint\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/utente/Desktop/MLA/progetto/NeHAR/post-optimization.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m                                        synapse\u001b[39m=\u001b[39msnn_parameters[\u001b[39m'\u001b[39m\u001b[39mnni_keras2snn_network/synapse/quniform\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/utente/Desktop/MLA/progetto/NeHAR/post-optimization.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m                                        )\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/utente/Desktop/MLA/progetto/NeHAR/post-optimization.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m##### neuron type now is:\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/utente/Desktop/MLA/progetto/NeHAR/post-optimization.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m ii \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(trained_converter\u001b[39m.\u001b[39mnet\u001b[39m.\u001b[39mensembles)):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'snn_parameters' is not defined"
     ]
    }
   ],
   "source": [
    "trained_converter = nengo_dl.Converter(model,\n",
    "                                       max_to_avg_pool=True,\n",
    "                                       swap_activations={tf.nn.relu: nengo.SpikingRectifiedLinear()},\n",
    "                                       scale_firing_rates=snn_parameters['nni_keras2snn_network/scale_firing_rates/randint'],\n",
    "                                       synapse=snn_parameters['nni_keras2snn_network/synapse/quniform'],\n",
    "                                       )\n",
    "\n",
    "print('\\n##### neuron type now is:')\n",
    "for ii in range(len(trained_converter.net.ensembles)):\n",
    "    print('In ensemble',ii,':',trained_converter.net.ensembles[ii].neuron_type)\n",
    "print('#########################\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f4c73bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(1, 2000, 1)]            0         \n",
      "                                                                 \n",
      " conv1d_86 (Conv1D)          (1, 2000, 4)              24        \n",
      "                                                                 \n",
      " conv1d_87 (Conv1D)          (1, 2000, 16)             336       \n",
      "                                                                 \n",
      " conv1d_88 (Conv1D)          (1, 400, 384)             117120    \n",
      "                                                                 \n",
      " lstm_74 (LSTM)              (1, 400, 384)             1181184   \n",
      "                                                                 \n",
      " lstm_75 (LSTM)              (1, 400, 384)             1181184   \n",
      "                                                                 \n",
      " lstm_76 (LSTM)              (1, 400, 384)             1181184   \n",
      "                                                                 \n",
      " lstm_77 (LSTM)              (1, 400, 384)             1181184   \n",
      "                                                                 \n",
      " lstm_78 (LSTM)              (1, 400, 384)             1181184   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,023,400\n",
      "Trainable params: 6,023,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/base_arch2/lib/python3.8/site-packages/nengo_dl/converter.py:324: UserWarning: Layer type LSTM does not have a registered converter. Falling back to TensorNode.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### neuron type now is:\n",
      "In ensemble 0 : SpikingRectifiedLinear(amplitude=0.01)\n",
      "In ensemble 1 : SpikingRectifiedLinear(amplitude=0.01)\n",
      "In ensemble 2 : SpikingRectifiedLinear(amplitude=0.01)\n",
      "#########################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(batch_shape=model.layers[0].input_shape, name='Input')\n",
    "prev_layer = input_layer\n",
    "for num,el in enumerate(model.layers):\n",
    "    prev_layer = el(prev_layer)\n",
    "\n",
    "model = Model([input_layer], [prev_layer])\n",
    "\n",
    "model.summary()\n",
    "#conversione modello keras bonitosnn\n",
    "trained_converter = nengo_dl.Converter(model,\n",
    "                                       max_to_avg_pool=True,\n",
    "                                       swap_activations={tf.nn.silu: nengo.SpikingRectifiedLinear()},\n",
    "                                       scale_firing_rates=100,\n",
    "                                       synapse=1e-2,\n",
    "                                       )\n",
    "\n",
    "print('\\n##### neuron type now is:')\n",
    "for ii in range(len(trained_converter.net.ensembles)):\n",
    "    print('In ensemble',ii,':',trained_converter.net.ensembles[ii].neuron_type)\n",
    "print('#########################\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "367c5416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(1, 400, 384), dtype=tf.float32, name=None), name='lstm_78/PartitionedCall:1', description=\"created by layer 'lstm_78'\")\n",
      "(<Reference wrapping <KerasTensor: shape=(1, 400, 384) dtype=float32 (created by layer 'lstm_78')>>,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(1, 2000, 4) dtype=float32 (created by layer 'conv1d_86')>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.output)\n",
    "for k in trained_converter.outputs.keys():\n",
    "    print(k)\n",
    "model.layers[1].get_output_at(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "through-people",
   "metadata": {},
   "outputs": [],
   "source": [
    "with trained_converter.net:\n",
    "    output_p = trained_converter.outputs[model.output]\n",
    "    conv0_p = nengo.Probe(trained_converter.layers[model.layers[1].get_output_at(-1)])\n",
    "    conv1_p = nengo.Probe(trained_converter.layers[model.layers[2].get_output_at(-1)])\n",
    "    conv2_p = nengo.Probe(trained_converter.layers[model.layers[3].get_output_at(-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "breeding-salon",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'snn_parameters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/utente/Desktop/MLA/progetto/NeHAR/post-optimization.ipynb Cell 54\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/utente/Desktop/MLA/progetto/NeHAR/post-optimization.ipynb#Y100sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m n_steps \u001b[39m=\u001b[39m snn_parameters[\u001b[39m'\u001b[39m\u001b[39mnni_keras2snn_network/n_steps/randint\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/utente/Desktop/MLA/progetto/NeHAR/post-optimization.ipynb#Y100sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m tiled_x_test \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mtile(x_test, (\u001b[39m1\u001b[39m, n_steps, \u001b[39m1\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'snn_parameters' is not defined"
     ]
    }
   ],
   "source": [
    "n_steps = snn_parameters['nni_keras2snn_network/n_steps/randint']\n",
    "\n",
    "tiled_x_test = np.tile(x_test, (1, n_steps, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "closing-oakland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|                     Building network (0%)                    | ETA:  --:--:--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|#                     Building network (2%)                     | ETA: 0:00:02\n",
      "|#                     Building network (2%)                     | ETA: 0:00:04\n",
      "|#                     Building network (2%)                     | ETA: 0:00:06\n",
      "|#                     Building network (2%)                     | ETA: 0:00:09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/base_arch2/lib/python3.8/site-packages/nengo_dl/simulator.py:460: UserWarning: No GPU support detected. See https://www.nengo.ai/nengo-dl/installation.html#installing-tensorflow for instructions on setting up TensorFlow with GPU support.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|##                    Building network (4%)                     | ETA: 0:00:05\n",
      "|##                    Building network (4%)                     | ETA: 0:00:06\n",
      "|##                    Building network (4%)                     | ETA: 0:00:07\n",
      "|##                    Building network (4%)                     | ETA: 0:00:08\n",
      "|##                    Building network (4%)                     | ETA: 0:00:10\n",
      "|##                    Building network (4%)                     | ETA: 0:00:11\n",
      "|##                    Building network (4%)                     | ETA: 0:00:12\n",
      "|##                    Building network (4%)                     | ETA: 0:00:13\n",
      "|##                    Building network (4%)                     | ETA: 0:00:14\n",
      "|##                    Building network (4%)                     | ETA: 0:00:15\n",
      "|##                    Building network (4%)                     | ETA: 0:00:16\n",
      "|##                    Building network (4%)                     | ETA: 0:00:17\n",
      "|##                    Building network (4%)                     | ETA: 0:00:18\n",
      "|##                    Building network (4%)                     | ETA: 0:00:20\n",
      "|##                    Building network (4%)                     | ETA: 0:00:21\n",
      "Build finished in 0:00:00\n",
      "|#                         Optimizing graph                           | 0:00:00\n",
      "|#             Optimizing graph: operator simplificaton               | 0:00:00\n",
      "Optimizing graph: operator simplificaton finished in 0:00:00\n",
      "|#                Optimizing graph: merging operators                 | 0:00:00\n",
      "Optimizing graph: merging operators finished in 0:00:00\n",
      "|#                Optimizing graph: ordering signals                  | 0:00:00\n",
      "Optimizing graph: ordering signals finished in 0:00:00\n",
      "| #                        Optimizing graph                           | 0:00:00\n",
      "|#                Optimizing graph: creating signals                  | 0:00:00\n",
      "Optimizing graph: creating signals finished in 0:00:00\n",
      "Optimization finished in 0:00:00\n",
      "|#                        Constructing graph                          | 0:00:00\n",
      "| #                       Constructing graph                          | 0:00:00\n",
      "|  #                      Constructing graph                          | 0:00:00\n",
      "|   #                     Constructing graph                          | 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/base_arch2/lib/python3.8/site-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/envs/base_arch2/lib/python3.8/site-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer Orthogonal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    #                    Constructing graph                          | 0:00:00\n",
      "|     #                   Constructing graph                          | 0:00:00\n",
      "|           Constructing graph: pre-build stage (0%)           | ETA:  --:--:--\n",
      "|      #                  Constructing graph                          | 0:00:00\n",
      "Constructing graph: pre-build stage finished in 0:00:00\n",
      "|             Constructing graph: build stage (0%)             | ETA:  --:--:--\n",
      "|             Constructing graph: build stage (0%)             | ETA:  --:--:--\n",
      "|             Constructing graph: build stage (0%)             | ETA:  --:--:--\n",
      "|##            Constructing graph: build stage (4%)              | ETA: 0:00:05\n",
      "|########      Constructing graph: build stage (13%)             | ETA: 0:00:01\n",
      "|###########   Constructing graph: build stage (18%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (22%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (27%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (34%)             | ETA: 0:00:00\n",
      "|##############Constructing graph: build stage (34%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (34%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (34%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (34%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (34%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (34%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (34%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (34%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (34%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (34%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (38%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (38%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (38%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (38%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (38%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (38%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (38%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (38%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (38%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (38%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (43%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (43%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (43%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (43%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (43%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (43%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (43%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (43%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (43%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (43%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (47%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (47%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (47%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (47%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (47%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (47%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (47%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (47%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (47%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (47%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (52%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (52%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (52%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (52%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (52%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (52%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (52%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (52%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (52%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (52%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (54%)             | ETA: 0:00:02\n",
      "|############Constructing graph: build stage (100%)############| ETA:  00:00:00\n",
      "|############Constructing graph: build stage (100%)############| ETA:  00:00:00\n",
      "|############Constructing graph: build stage (100%)############| ETA:  00:00:00\n",
      "|############Constructing graph: build stage (100%)############| ETA:  00:00:00\n",
      "|############Constructing graph: build stage (100%)############| ETA:  00:00:00\n",
      "|############Constructing graph: build stage (100%)############| ETA:  00:00:00\n",
      "|############Constructing graph: build stage (100%)############| ETA:  00:00:00\n",
      "|############Constructing graph: build stage (100%)############| ETA:  00:00:00\n",
      "|############Constructing graph: build stage (100%)############| ETA:  00:00:00\n",
      "Constructing graph: build stage finished in 0:00:03\n",
      "|                         Constructing graph                          | 0:00:04\n",
      "Construction finished in 0:00:04\n",
      "\n",
      "=================================================================\n",
      "Total params: 6,217,000\n",
      "Trainable params: 6,023,400\n",
      "Non-trainable params: 193,600\n",
      "_________________________________________________________________\n",
      "\n",
      "Memory footprint (MB): 24.868\n",
      "Total: 6217000\n",
      "Missed: 0\n",
      "\n",
      "\n",
      "|           Constructing graph: pre-build stage (0%)           | ETA:  --:--:--\n",
      "|############Constructing graph: pre-build stage (61%)           | ETA: 0:00:00\n",
      "Constructing graph: pre-build stage finished in 0:00:00\n",
      "|             Constructing graph: build stage (0%)             | ETA:  --:--:--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/base_arch2/lib/python3.8/site-packages/nengo_dl/simulator.py:1765: UserWarning: Number of elements (1) in ['str'] does not match number of Probes (16); consider using an explicit input dictionary in this case, so that the assignment of data to objects is unambiguous.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|             Constructing graph: build stage (0%)             | ETA:  --:--:--\n",
      "|             Constructing graph: build stage (0%)             | ETA:  --:--:--\n",
      "|##            Constructing graph: build stage (4%)              | ETA: 0:00:05\n",
      "|########      Constructing graph: build stage (13%)             | ETA: 0:00:01\n",
      "|###########   Constructing graph: build stage (18%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (25%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (31%)             | ETA: 0:00:00\n",
      "|##############Constructing graph: build stage (34%)             | ETA: 0:00:00\n",
      "|##############Constructing graph: build stage (34%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (34%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (34%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (34%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (34%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (34%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (34%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (34%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (34%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (34%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (34%)             | ETA: 0:00:03\n",
      "|##############Constructing graph: build stage (34%)             | ETA: 0:00:03\n",
      "|##############Constructing graph: build stage (34%)             | ETA: 0:00:03\n",
      "|##############Constructing graph: build stage (34%)             | ETA: 0:00:03\n",
      "|##############Constructing graph: build stage (34%)             | ETA: 0:00:03\n",
      "|##############Constructing graph: build stage (34%)             | ETA: 0:00:03\n",
      "|##############Constructing graph: build stage (34%)             | ETA: 0:00:03\n",
      "|##############Constructing graph: build stage (34%)             | ETA: 0:00:03\n",
      "|##############Constructing graph: build stage (34%)             | ETA: 0:00:03\n",
      "|##############Constructing graph: build stage (34%)             | ETA: 0:00:03\n",
      "|##############Constructing graph: build stage (34%)             | ETA: 0:00:04\n",
      "|##############Constructing graph: build stage (38%)             | ETA: 0:00:03\n",
      "|##############Constructing graph: build stage (38%)             | ETA: 0:00:03\n",
      "|##############Constructing graph: build stage (38%)             | ETA: 0:00:03\n",
      "|##############Constructing graph: build stage (38%)             | ETA: 0:00:03\n",
      "|##############Constructing graph: build stage (38%)             | ETA: 0:00:03\n",
      "|##############Constructing graph: build stage (38%)             | ETA: 0:00:03\n",
      "|##############Constructing graph: build stage (38%)             | ETA: 0:00:03\n",
      "|##############Constructing graph: build stage (38%)             | ETA: 0:00:03\n",
      "|##############Constructing graph: build stage (38%)             | ETA: 0:00:04\n",
      "|##############Constructing graph: build stage (43%)             | ETA: 0:00:03\n",
      "|##############Constructing graph: build stage (43%)             | ETA: 0:00:03\n",
      "|##############Constructing graph: build stage (43%)             | ETA: 0:00:03\n",
      "|##############Constructing graph: build stage (43%)             | ETA: 0:00:03\n",
      "|##############Constructing graph: build stage (43%)             | ETA: 0:00:03\n",
      "|##############Constructing graph: build stage (43%)             | ETA: 0:00:03\n",
      "|##############Constructing graph: build stage (43%)             | ETA: 0:00:03\n",
      "|##############Constructing graph: build stage (43%)             | ETA: 0:00:03\n",
      "|##############Constructing graph: build stage (43%)             | ETA: 0:00:03\n",
      "|##############Constructing graph: build stage (47%)             | ETA: 0:00:03\n",
      "|##############Constructing graph: build stage (47%)             | ETA: 0:00:03\n",
      "|##############Constructing graph: build stage (47%)             | ETA: 0:00:03\n",
      "|##############Constructing graph: build stage (47%)             | ETA: 0:00:03\n",
      "|##############Constructing graph: build stage (47%)             | ETA: 0:00:03\n",
      "|##############Constructing graph: build stage (47%)             | ETA: 0:00:03\n",
      "|##############Constructing graph: build stage (47%)             | ETA: 0:00:03\n",
      "|##############Constructing graph: build stage (47%)             | ETA: 0:00:03\n",
      "|##############Constructing graph: build stage (47%)             | ETA: 0:00:03\n",
      "|##############Constructing graph: build stage (52%)             | ETA: 0:00:03\n",
      "|##############Constructing graph: build stage (52%)             | ETA: 0:00:03\n",
      "|##############Constructing graph: build stage (52%)             | ETA: 0:00:03\n",
      "|##############Constructing graph: build stage (52%)             | ETA: 0:00:03\n",
      "|##############Constructing graph: build stage (52%)             | ETA: 0:00:03\n",
      "|##############Constructing graph: build stage (52%)             | ETA: 0:00:03\n",
      "|##############Constructing graph: build stage (52%)             | ETA: 0:00:03\n",
      "|##############Constructing graph: build stage (52%)             | ETA: 0:00:03\n",
      "|##############Constructing graph: build stage (54%)             | ETA: 0:00:03\n",
      "|############Constructing graph: build stage (100%)############| ETA:  00:00:00\n",
      "|############Constructing graph: build stage (100%)############| ETA:  00:00:00\n",
      "|############Constructing graph: build stage (100%)############| ETA:  00:00:00\n",
      "|############Constructing graph: build stage (100%)############| ETA:  00:00:00\n",
      "|############Constructing graph: build stage (100%)############| ETA:  00:00:00\n",
      "|############Constructing graph: build stage (100%)############| ETA:  00:00:00\n",
      "|############Constructing graph: build stage (100%)############| ETA:  00:00:00\n",
      "|############Constructing graph: build stage (100%)############| ETA:  00:00:00\n",
      "|############Constructing graph: build stage (100%)############| ETA:  00:00:00\n",
      "|############Constructing graph: build stage (100%)############| ETA:  00:00:00\n",
      "|############Constructing graph: build stage (100%)############| ETA:  00:00:00\n",
      "|############Constructing graph: build stage (100%)############| ETA:  00:00:00\n",
      "Constructing graph: build stage finished in 0:00:04\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc76fe91af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc76fe91af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 9s 9s/step\n",
      "Test accuracy: 0.0%\n"
     ]
    }
   ],
   "source": [
    "with nengo_dl.Simulator(trained_converter.net, minibatch_size=1) as sim:\n",
    "    snn_model_summary = sim.keras_model\n",
    "    snn_params = sum(np.prod(s.shape) for s in snn_model_summary.weights)\n",
    "    snn_trainable_params = sum(np.prod(w.shape) for w in snn_model_summary.trainable_weights)\n",
    "    print('\\n=================================================================')\n",
    "    print('Total params:','{:,d}'.format(snn_params))\n",
    "    print('Trainable params:','{:,d}'.format(snn_trainable_params))\n",
    "    print('Non-trainable params:','{:,d}'.format(snn_params-snn_trainable_params))\n",
    "    print('_________________________________________________________________\\n')\n",
    "    \n",
    "    mem_fp, total, missed = memory_footprint(sim)\n",
    "\n",
    "    print('Memory footprint (MB):',np.round(mem_fp,4))\n",
    "    print('Total:',total)\n",
    "    print('Missed:',missed)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    sim.compile(\n",
    "                optimizer=tf.optimizers.Adam(0.0003),\n",
    "                loss={\n",
    "                      output_p: tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                      conv0_p: tf.losses.mse,\n",
    "                      conv1_p: tf.losses.mse,\n",
    "                     },\n",
    "                loss_weights={\n",
    "                              output_p: 1, \n",
    "                              conv0_p: 1e-3,#snn_parameters['nni_keras2snn_network/reg_conv0/quniform'], \n",
    "                              conv1_p: 1e-3,#snn_parameters['nni_keras2snn_network/reg_conv1/quniform']\n",
    "                              conv1_p: 1e-3,\n",
    "                             },\n",
    "                metrics=[\"accuracy\"],\n",
    "               )\n",
    "    \n",
    "    #sim.load_params(\"./output/tmp_s{}_{}_{}/best_test_{}\".format(net_type,snn_nni_experiment,datafile[5:],snn_nni_experiment))\n",
    "        \n",
    "    data = sim.predict({trained_converter.inputs[model.input]: x_bonito}) #tiled_x_test\n",
    "    predictions = np.argmax(data[trained_converter.outputs[model.output]][:, -1], axis=-1)\n",
    "    test_accuracy = (predictions[:] == y_test[:predictions.shape[0], 0, 0]).mean()\n",
    "    print(\"Test accuracy: \"+str(np.round(test_accuracy*100,2))+\"%\")\n",
    "    \n",
    "    save = True\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_test[:np.min([len(y_test), len(predictions)]),-1,-1], predictions[:np.min([len(y_test), len(predictions)])], normalize='true')\n",
    "    labels = ConfusionMatrix_labels(subset)\n",
    "    cm_df = pd.DataFrame(cm, index=[ii for ii in labels], columns=[jj for jj in labels])\n",
    "    plt.figure(figsize=(7,5.25))\n",
    "    sn.heatmap(cm_df,\n",
    "               annot=True,\n",
    "               fmt='.2g',\n",
    "               cbar=False,\n",
    "               square=False,\n",
    "               cmap=\"YlGnBu\")\n",
    "    plt.xlabel('\\nPredicted')\n",
    "    plt.ylabel('True\\n')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.title('Spiking CNN\\n', fontweight='bold', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        plt.savefig('./pictures/'+model_name+'_'+snn_nni_experiment+'_'+snn_nni_trial+'.png')\n",
    "    plt.show()\n",
    "    \"\"\"\n",
    "sim.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "incomplete-european",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|#                     Building network (2%)                     | ETA: 0:00:02\n",
      "|#                     Building network (2%)                     | ETA: 0:00:04\n",
      "|#                     Building network (2%)                     | ETA: 0:00:06\n",
      "|#                     Building network (2%)                     | ETA: 0:00:08\n",
      "|##                    Building network (4%)                     | ETA: 0:00:05\n",
      "|##                    Building network (4%)                     | ETA: 0:00:06\n",
      "|##                    Building network (4%)                     | ETA: 0:00:07\n",
      "|##                    Building network (4%)                     | ETA: 0:00:08\n",
      "|##                    Building network (4%)                     | ETA: 0:00:09\n",
      "|##                    Building network (4%)                     | ETA: 0:00:10\n",
      "|##                    Building network (4%)                     | ETA: 0:00:11\n",
      "|##                    Building network (4%)                     | ETA: 0:00:12\n",
      "|##                    Building network (4%)                     | ETA: 0:00:13\n",
      "|##                    Building network (4%)                     | ETA: 0:00:14\n",
      "|##                    Building network (4%)                     | ETA: 0:00:15\n",
      "|##                    Building network (4%)                     | ETA: 0:00:16\n",
      "|##                    Building network (4%)                     | ETA: 0:00:17\n",
      "|##                    Building network (4%)                     | ETA: 0:00:18\n",
      "|##                    Building network (4%)                     | ETA: 0:00:19\n",
      "|##                    Building network (4%)                     | ETA: 0:00:20\n",
      "|##                    Building network (4%)                     | ETA: 0:00:21\n",
      "Build finished in 0:00:01\n",
      "|#                         Optimizing graph                           | 0:00:00\n",
      "|#             Optimizing graph: operator simplificaton               | 0:00:00\n",
      "Optimizing graph: operator simplificaton finished in 0:00:00\n",
      "|#                Optimizing graph: merging operators                 | 0:00:00\n",
      "Optimizing graph: merging operators finished in 0:00:00\n",
      "|#                Optimizing graph: ordering signals                  | 0:00:00\n",
      "Optimizing graph: ordering signals finished in 0:00:00\n",
      "|#                Optimizing graph: creating signals                  | 0:00:00\n",
      "Optimizing graph: creating signals finished in 0:00:00\n",
      "| #                        Optimizing graph                           | 0:00:00\n",
      "Optimization finished in 0:00:00\n",
      "|#                        Constructing graph                          | 0:00:00\n",
      "| #                       Constructing graph                          | 0:00:00\n",
      "|  #                      Constructing graph                          | 0:00:00\n",
      "|   #                     Constructing graph                          | 0:00:00\n",
      "|    #                    Constructing graph                          | 0:00:00\n",
      "|     #                   Constructing graph                          | 0:00:00\n",
      "|           Constructing graph: pre-build stage (0%)           | ETA:  --:--:--\n",
      "|############Constructing graph: pre-build stage (65%)           | ETA: 0:00:00\n",
      "Constructing graph: pre-build stage finished in 0:00:00\n",
      "|             Constructing graph: build stage (0%)             | ETA:  --:--:--\n",
      "|             Constructing graph: build stage (0%)             | ETA:  --:--:--\n",
      "|#             Constructing graph: build stage (2%)              | ETA: 0:00:07\n",
      "|###           Constructing graph: build stage (4%)              | ETA: 0:00:04\n",
      "|##########    Constructing graph: build stage (17%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (21%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (29%)             | ETA: 0:00:00\n",
      "|##############Constructing graph: build stage (36%)             | ETA: 0:00:00\n",
      "|##############Constructing graph: build stage (36%)             | ETA: 0:00:00\n",
      "|##############Constructing graph: build stage (36%)             | ETA: 0:00:00\n",
      "|##############Constructing graph: build stage (36%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (36%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (36%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (36%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (36%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (36%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (41%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (41%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (41%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (41%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (41%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (41%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (41%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (41%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (41%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (41%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (46%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (46%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (46%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (46%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (46%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (46%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (46%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (46%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (46%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (46%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (51%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (51%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (51%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (51%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (51%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (51%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (51%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (51%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (51%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (51%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (56%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (56%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (56%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (56%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (56%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (56%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (56%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (56%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (56%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (56%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (56%)             | ETA: 0:00:02\n",
      "|##############Constructing graph: build stage (63%)             | ETA: 0:00:01\n",
      "|############Constructing graph: build stage (100%)############| ETA:  00:00:00\n",
      "|############Constructing graph: build stage (100%)############| ETA:  00:00:00\n",
      "|############Constructing graph: build stage (100%)############| ETA:  00:00:00\n",
      "|############Constructing graph: build stage (100%)############| ETA:  00:00:00\n",
      "|############Constructing graph: build stage (100%)############| ETA:  00:00:00\n",
      "|############Constructing graph: build stage (100%)############| ETA:  00:00:00\n",
      "|############Constructing graph: build stage (100%)############| ETA:  00:00:00\n",
      "Constructing graph: build stage finished in 0:00:03\n",
      "|                         Constructing graph                          | 0:00:03\n",
      "Construction finished in 0:00:04\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'list' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/utente/Desktop/MLA/progetto/NeHAR/post-optimization.ipynb Cell 56\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/utente/Desktop/MLA/progetto/NeHAR/post-optimization.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m get_sops_spikingCNN(trained_converter\u001b[39m.\u001b[39;49mnet)\n",
      "\u001b[1;32m/mnt/c/Users/utente/Desktop/MLA/progetto/NeHAR/post-optimization.ipynb Cell 56\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/utente/Desktop/MLA/progetto/NeHAR/post-optimization.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m     simulation_steps \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mlen\u001b[39m(x_test[ii])) \u001b[39m#tiled_x_test\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/utente/Desktop/MLA/progetto/NeHAR/post-optimization.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m     sim\u001b[39m.\u001b[39mrun_steps(simulation_steps, data\u001b[39m=\u001b[39m{net\u001b[39m.\u001b[39mall_nodes[\u001b[39m0\u001b[39m]: x_bonito[ii][np\u001b[39m.\u001b[39mnewaxis,:,:]}) \u001b[39m#tiled_x_test\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/utente/Desktop/MLA/progetto/NeHAR/post-optimization.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m spikes_conv0 \u001b[39m=\u001b[39m sim\u001b[39m.\u001b[39;49mdata[conv0_p]\u001b[39m/\u001b[39;49m(\u001b[39m1\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m100\u001b[39;49m)\u001b[39m*\u001b[39mdt \u001b[39m#snn_parameters['nni_keras2snn_network/scale_firing_rates/randint']\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/utente/Desktop/MLA/progetto/NeHAR/post-optimization.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m spikes_conv1 \u001b[39m=\u001b[39m sim\u001b[39m.\u001b[39mdata[conv1_p]\u001b[39m/\u001b[39m(\u001b[39m1\u001b[39m\u001b[39m/\u001b[39m\u001b[39m100\u001b[39m)\u001b[39m*\u001b[39mdt\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/utente/Desktop/MLA/progetto/NeHAR/post-optimization.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m spikes_dense \u001b[39m=\u001b[39m sim\u001b[39m.\u001b[39mdata[dense_p]\u001b[39m/\u001b[39m(\u001b[39m1\u001b[39m\u001b[39m/\u001b[39m\u001b[39m100\u001b[39m)\u001b[39m*\u001b[39mdt\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'list' and 'float'"
     ]
    }
   ],
   "source": [
    "get_sops_spikingCNN(trained_converter.net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "23d45573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim.data[conv0_p]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-martial",
   "metadata": {},
   "source": [
    "<a id='Section_4'></a>\n",
    "### LMU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-reproduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# set seed to ensure the examples are reproducible\n",
    "seed = 0\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-morgan",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_type = 'LMU'\n",
    "\n",
    "device = 'watch'\n",
    "subset = 2\n",
    "time_window = 2\n",
    "\n",
    "window_size = 20*time_window # 20 Hz sampling times the temporal length of the window\n",
    "\n",
    "datafile = 'data_'+device+'_subset'+str(subset)+'_'+str(window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-ordinary",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"LMU_{}_subset{}_{}\".format(device,subset_window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parallel-president",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### GET NETWORK STRUCTURE PARAMETERS #####\n",
    "optim_nni_experiment = ''\n",
    "optim_nni_trial = ''\n",
    "optim_filename = 'parameter.cfg'\n",
    "optim_nni_ref = 'nni-experiments/'+optim_nni_experiment+'/trials/'+optim_nni_trial\n",
    "optim_nni_dir = os.path.expanduser('~')\n",
    "optim_filepath = os.path.join(optim_nni_dir,optim_nni_ref,optim_filename)\n",
    "\n",
    "with open(optim_filepath, 'r') as f:\n",
    "    data = f.read()\n",
    "\n",
    "params = json.loads(data)\n",
    "network_parameters = params['parameters']\n",
    "\n",
    "minibatch_train = network_parameters['minibatch']\n",
    "###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imported-civilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, x_val, x_test, y_train_oh, y_val_oh, y_test_oh) = load_wisdm2_data(datafile)\n",
    "timesteps = len(x_train[0])\n",
    "input_dim = len(x_train[0][0])\n",
    "n_classes = len(y_train_oh[0])\n",
    "\n",
    "y_train = np.argmax(y_train_oh, axis=-1)\n",
    "y_val = np.argmax(y_val_oh, axis=-1)\n",
    "y_test = np.argmax(y_test_oh, axis=-1)\n",
    "\n",
    "print('timesteps:',timesteps)\n",
    "print('input_dim:',input_dim)\n",
    "print('n_classes:',n_classes)\n",
    "\n",
    "y_train = y_train[:, None, None]\n",
    "y_test = y_test[:, None, None]\n",
    "y_val = y_val[:, None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-premium",
   "metadata": {},
   "outputs": [],
   "source": [
    "with nengo.Network(seed=seed) as net:\n",
    "    # remove some unnecessary features to speed up the training\n",
    "    nengo_dl.configure_settings(\n",
    "                                trainable=None,\n",
    "                                stateful=False,\n",
    "                                keep_history=False,\n",
    "                               )\n",
    "\n",
    "    # input node\n",
    "    inp = nengo.Node(np.zeros(input_dim))\n",
    "\n",
    "    # lmu cell\n",
    "    lmu = LMUCell(\n",
    "                  units=int(network_parameters['units']), \n",
    "                  order=int(network_parameters['order']), \n",
    "                  theta=network_parameters['theta'],\n",
    "                  input_d=input_dim,\n",
    "                  tau=network_parameters['tau'],\n",
    "                )\n",
    "    conn_in = nengo.Connection(inp, lmu.x, synapse=network_parameters['synapse_in'])\n",
    "    net.config[conn_in].trainable = True\n",
    "\n",
    "    # dense linear readout\n",
    "    out = nengo.Node(size_in=n_classes)\n",
    "    conn_out = nengo.Connection(lmu.h, out, transform=nengo_dl.dists.Glorot(), synapse=network_parameters['synapse_out'])\n",
    "    net.config[conn_out].trainable = True\n",
    "\n",
    "    # record output\n",
    "    p = nengo.Probe(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-highland",
   "metadata": {},
   "outputs": [],
   "source": [
    "with nengo_dl.Simulator(net, minibatch_size=minibatch_train) as sim:\n",
    "    \n",
    "    lmu_model_summary = sim.keras_model\n",
    "    lmu_params = sum(np.prod(s.shape) for s in lmu_model_summary.weights)\n",
    "    lmu_trainable_params = sum(np.prod(w.shape) for w in lmu_model_summary.trainable_weights)\n",
    "    mem_fp, total, missed = memory_footprint(sim) \n",
    "    print('\\n=================================================================')\n",
    "    print('Total params:','{:,d}'.format(lmu_params))\n",
    "    print('Trainable params:','{:,d}'.format(lmu_trainable_params))\n",
    "    print('Non-trainable params:','{:,d}'.format(lmu_params-lmu_trainable_params))\n",
    "    print('_________________________________________________________________\\n')\n",
    "    \n",
    "    mem_fp, total, missed = memory_footprint(sim)\n",
    "\n",
    "    print('Memory footprint (MB):',np.round(mem_fp,4))\n",
    "    print('Total:',total)\n",
    "    print('Missed:',missed)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    sim.compile(\n",
    "                loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                optimizer=tf.optimizers.Adam(network_parameters['lr']),\n",
    "                metrics=[\"accuracy\"],\n",
    "               )\n",
    "    \n",
    "    sim.load_params(\"./output/tmp_{}_{}_{}/best_test_{}\".format(net_type,snn_nni_experiment,datafile[5:],snn_nni_experiment))\n",
    "    \n",
    "    test = sim.evaluate(x_test, y_test)[\"probe_accuracy\"]\n",
    "    print(\"Test accuracy: \"+str(np.round(test*100,2))+\"%\")\n",
    "    \n",
    "    prediction = sim.predict(x_test)\n",
    "        \n",
    "    predictions = list(prediction.values())[0]\n",
    "    pred = predictions.argmax(axis=-1)\n",
    "    \n",
    "    save = False\n",
    "    \n",
    "    cm = confusion_matrix(y_test[:np.min([len(y_test), len(pred)]),-1,-1], pred[:np.min([len(y_test), len(pred)]),-1], normalize='true')\n",
    "    labels = ConfusionMatrix_labels(subset)\n",
    "    cm_df = pd.DataFrame(cm, index=[ii for ii in labels], columns=[jj for jj in labels])\n",
    "    plt.figure(figsize=(7,5.25))\n",
    "    sn.heatmap(cm_df,\n",
    "               annot=True,\n",
    "               fmt='.2g',\n",
    "               cbar=False,\n",
    "               square=False,\n",
    "               cmap=\"YlGnBu\")\n",
    "    plt.xlabel('\\nPredicted')\n",
    "    plt.ylabel('True\\n')\n",
    "    plt.title('LMU\\n', fontweight='bold', fontsize=16)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        plt.savefig('./pictures/'+model_name+'_'+optim_nni_experiment+'_'+optim_nni_trial+'.png')\n",
    "    plt.show()\n",
    "\n",
    "sim.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressing-soldier",
   "metadata": {},
   "source": [
    "<a id='Section_5'></a>\n",
    "### Spiking LMU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-madison",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# set seed to ensure the examples are reproducible\n",
    "seed = 0\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "institutional-effectiveness",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_type = 'slmu'\n",
    "\n",
    "device = 'watch'\n",
    "subset = 2\n",
    "time_window = 2\n",
    "\n",
    "window_size = 20*time_window # 20 Hz sampling times the temporal length of the window\n",
    "\n",
    "datafile = 'data_'+device+'_subset'+str(subset)+'_'+str(window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-buying",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"sLMU_{}_subset{}_{}\".format(device,subset_window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-marathon",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### GET NETWORK STRUCTURE PARAMETERS #####\n",
    "optim_nni_experiment = ''\n",
    "optim_nni_trial = ''\n",
    "optim_filename = 'parameter.cfg'\n",
    "optim_nni_ref = 'nni-experiments/'+optim_nni_experiment+'/trials/'+optim_nni_trial\n",
    "optim_nni_dir = os.path.expanduser('~')\n",
    "optim_filepath = os.path.join(optim_nni_dir,optim_nni_ref,optim_filename)\n",
    "\n",
    "with open(optim_filepath, 'r') as f:\n",
    "    data = f.read()\n",
    "\n",
    "params = json.loads(data)\n",
    "network_parameters = params['parameters']\n",
    "\n",
    "minibatch_train = network_parameters['minibatch']\n",
    "###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-calculator",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, x_val, x_test, y_train_oh, y_val_oh, y_test_oh) = load_wisdm2_data(datafile)\n",
    "timesteps = len(x_train[0])\n",
    "input_dim = len(x_train[0][0])\n",
    "n_classes = len(y_train_oh[0])\n",
    "\n",
    "y_train = np.argmax(y_train_oh, axis=-1)\n",
    "y_val = np.argmax(y_val_oh, axis=-1)\n",
    "y_test = np.argmax(y_test_oh, axis=-1)\n",
    "\n",
    "print('timesteps:',timesteps)\n",
    "print('input_dim:',input_dim)\n",
    "print('n_classes:',n_classes)\n",
    "\n",
    "y_train = y_train[:, None, None]\n",
    "y_test = y_test[:, None, None]\n",
    "y_val = y_val[:, None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-latest",
   "metadata": {},
   "outputs": [],
   "source": [
    "with nengo.Network(seed=seed) as net:\n",
    "    # remove some unnecessary features to speed up the training\n",
    "    nengo_dl.configure_settings(\n",
    "        trainable=None,\n",
    "        stateful=False,\n",
    "        keep_history=False,\n",
    "    )\n",
    "\n",
    "    # input node\n",
    "    inp = nengo.Node(np.zeros(input_dim))\n",
    "    \n",
    "    order = int(network_parameters['order'])\n",
    "    theta = network_parameters['theta']\n",
    "    input_d = input_dim\n",
    "    tau = network_parameters['tau'] \n",
    "    \n",
    "    Q = np.arange(order, dtype=np.float64)\n",
    "    R = (2 * Q + 1)[:, None] / theta\n",
    "    j, i = np.meshgrid(Q, Q)\n",
    "    A = np.where(i < j, -1, (-1.0) ** (i - j + 1)) * R \n",
    "    B = (-1.0) ** Q[:, None] * R \n",
    "    C = np.ones((1, order))\n",
    "    D = np.zeros((1,))\n",
    "\n",
    "    disc_step = 1/theta\n",
    "    A, B, _, _, _ = cont2discrete((A, B, C, D), dt=disc_step, method=\"zoh\")\n",
    "    \n",
    "    A_H = 1/(1-np.exp(-disc_step/tau)) * (A - np.exp(-disc_step/tau)*np.identity(order))\n",
    "    B_H = 1/(1-np.exp(-disc_step/tau)) * B\n",
    "\n",
    "    for conn in net.all_connections:\n",
    "        conn.synapse = network_parameters['synapse_all']\n",
    "\n",
    "    max_rate = network_parameters['max_rate']\n",
    "    amplitude = 1/max_rate\n",
    "    lmu_inner = nengo.networks.EnsembleArray(n_neurons=int(network_parameters['n_neurons']),\n",
    "                                             n_ensembles=order, \n",
    "                                             neuron_type=nengo.SpikingRectifiedLinear(amplitude=amplitude),\n",
    "                                             max_rates=nengo.dists.Choice([max_rate]))\n",
    "    conn_inner = nengo.Connection(lmu_inner.output, lmu_inner.input, transform=A_H, synapse=tau)\n",
    "    net.config[conn_inner].trainable = True\n",
    "    \n",
    "    conn_in = nengo.Connection(inp, lmu_inner.input, transform=np.ones((1, input_d))*B_H, synapse=network_parameters['synapse_in'])\n",
    "    net.config[conn_in].trainable = True\n",
    "    \n",
    "    # dense linear readout\n",
    "    out = nengo.Node(size_in=n_classes)\n",
    "    conn_out = nengo.Connection(lmu_inner.output, out, transform=nengo_dl.dists.Glorot(), synapse=network_parameters['synapse_out'])\n",
    "    net.config[conn_out].trainable = True\n",
    "\n",
    "    # record output\n",
    "    p = nengo.Probe(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-underground",
   "metadata": {},
   "outputs": [],
   "source": [
    "with nengo_dl.Simulator(net, minibatch_size=minibatch_train) as sim: \n",
    "    \n",
    "    lmuEns_model_summary = sim.keras_model\n",
    "    lmuEns_params = sum(np.prod(s.shape) for s in lmuEns_model_summary.weights)\n",
    "    lmuEns_trainable_params = sum(np.prod(w.shape) for w in lmuEns_model_summary.trainable_weights)\n",
    "    mem_fp, total, missed = memory_footprint(sim) \n",
    "    print('\\n=================================================================')\n",
    "    print('Total params:','{:,d}'.format(lmuEns_params))\n",
    "    print('Trainable params:','{:,d}'.format(lmuEns_trainable_params))\n",
    "    print('Non-trainable params:','{:,d}'.format(lmuEns_params-lmuEns_trainable_params))\n",
    "    print('_________________________________________________________________\\n')\n",
    "    \n",
    "    mem_fp, total, missed = memory_footprint(sim)\n",
    "\n",
    "    print('Memory footprint (MB):',np.round(mem_fp,4))\n",
    "    print('Total:',total)\n",
    "    print('Missed:',missed)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    sim.compile(\n",
    "                loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                optimizer=tf.optimizers.Adam(network_parameters['lr']),\n",
    "                metrics=[\"accuracy\"],\n",
    "               )\n",
    "    \n",
    "    sim.load_params(\"./output/tmp_s{}_{}_{}/best_test_{}\".format(net_type,snn_nni_experiment,datafile[5:],snn_nni_experiment))\n",
    "    \n",
    "    test = sim.evaluate(x_test, y_test)[\"probe_accuracy\"]\n",
    "    print(\"Test accuracy: \"+str(np.round(test*100,2))+\"%\")\n",
    "    \n",
    "    prediction = sim.predict(x_test)\n",
    "        \n",
    "    predictions = list(prediction.values())[0]\n",
    "    pred = predictions.argmax(axis=-1)\n",
    "    \n",
    "    save = False\n",
    "    \n",
    "    cm = confusion_matrix(y_test[:np.min([len(y_test), len(pred)]),-1,-1], pred[:np.min([len(y_test), len(pred)]),-1], normalize='true')\n",
    "    labels = ConfusionMatrix_labels(subset)\n",
    "    cm_df = pd.DataFrame(cm, index=[ii for ii in labels], columns=[jj for jj in labels])\n",
    "    plt.figure(figsize=(7,5.25))\n",
    "    sn.heatmap(cm_df,\n",
    "               annot=True,\n",
    "               fmt='.2g',\n",
    "               cbar=False,\n",
    "               square=False,\n",
    "               cmap=\"YlGnBu\")\n",
    "    plt.xlabel('\\nPredicted')\n",
    "    plt.ylabel('True\\n')\n",
    "    plt.title('Spiking LMU\\n', fontweight='bold', fontsize=16)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        plt.savefig('./pictures/'+model_name+'_'+optim_nni_experiment+'_'+optim_nni_trial+'.png')\n",
    "    plt.show()\n",
    "\n",
    "sim.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-flesh",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_sops_LMUens(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "useful-lounge",
   "metadata": {},
   "source": [
    "<a id='Section_6'></a>\n",
    "### LMU (ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revolutionary-choice",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# set seed to ensure the examples are reproducible\n",
    "seed = 0\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genetic-complaint",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_type = 'LMU'\n",
    "\n",
    "device = 'watch'\n",
    "subset = 2\n",
    "time_window = 2\n",
    "\n",
    "window_size = 20*time_window # 20 Hz sampling times the temporal length of the window\n",
    "\n",
    "datafile = 'data_'+device+'_subset'+str(subset)+'_'+str(window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flexible-cattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"LMU_freqdec_{}_subset{}_{}\".format(device,subset_window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-packaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### GET NETWORK STRUCTURE PARAMETERS #####\n",
    "optim_nni_experiment = ''\n",
    "optim_nni_trial = ''\n",
    "optim_filename = 'parameter.cfg'\n",
    "optim_nni_ref = 'nni-experiments/'+optim_nni_experiment+'/trials/'+optim_nni_trial\n",
    "optim_nni_dir = os.path.expanduser('~')\n",
    "optim_filepath = os.path.join(optim_nni_dir,optim_nni_ref,optim_filename)\n",
    "\n",
    "with open(optim_filepath, 'r') as f:\n",
    "    data = f.read()\n",
    "\n",
    "params = json.loads(data)\n",
    "network_parameters = params['parameters']\n",
    "\n",
    "minibatch_train = network_parameters['minibatch']\n",
    "###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-conditioning",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dec = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-acrobat",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, x_val, x_test, y_train_oh, y_val_oh, y_test_oh) = load_wisdm2_data(datafile)\n",
    "\n",
    "if freq_dec:\n",
    "    x_train = frequency_decomposition(x_train)\n",
    "    x_val = frequency_decomposition(x_val)\n",
    "    x_test = frequency_decomposition(x_test)\n",
    "\n",
    "timesteps = len(x_train[0])\n",
    "input_dim = len(x_train[0][0])\n",
    "n_classes = len(y_train_oh[0])\n",
    "\n",
    "y_train = np.argmax(y_train_oh, axis=-1)\n",
    "y_val = np.argmax(y_val_oh, axis=-1)\n",
    "y_test = np.argmax(y_test_oh, axis=-1)\n",
    "\n",
    "print('timesteps:',timesteps)\n",
    "print('input_dim:',input_dim)\n",
    "print('n_classes:',n_classes)\n",
    "\n",
    "y_train = y_train[:, None, None]\n",
    "y_test = y_test[:, None, None]\n",
    "y_val = y_val[:, None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corrected-indie",
   "metadata": {},
   "outputs": [],
   "source": [
    "with nengo.Network(seed=seed) as net:\n",
    "    # remove some unnecessary features to speed up the training\n",
    "    nengo_dl.configure_settings(\n",
    "                                trainable=None,\n",
    "                                stateful=False,\n",
    "                                keep_history=False,\n",
    "                               )\n",
    "\n",
    "    # input node\n",
    "    inp = nengo.Node(np.zeros(input_dim))\n",
    "\n",
    "    # lmu cell\n",
    "    lmu = LMUCell(\n",
    "                  units=int(network_parameters['units']),\n",
    "                  order=int(network_parameters['order']), \n",
    "                  theta=network_parameters['theta'], \n",
    "                  input_d=input_dim,\n",
    "                  tau=network_parameters['tau'],\n",
    "                )\n",
    "    conn_in = nengo.Connection(inp, lmu.x, synapse=network_parameters['synapse_in'])\n",
    "    net.config[conn_in].trainable = True\n",
    "\n",
    "    # dense linear readout\n",
    "    out = nengo.Node(size_in=n_classes)\n",
    "    conn_out = nengo.Connection(lmu.h, out, transform=nengo_dl.dists.Glorot(), synapse=network_parameters['synapse_out'])\n",
    "    net.config[conn_out].trainable = True\n",
    "\n",
    "    # record output\n",
    "    p = nengo.Probe(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-civilization",
   "metadata": {},
   "outputs": [],
   "source": [
    "with nengo_dl.Simulator(net, minibatch_size=minibatch_train) as sim:\n",
    "    \n",
    "    lmu_model_summary = sim.keras_model\n",
    "    lmu_params = sum(np.prod(s.shape) for s in lmu_model_summary.weights)\n",
    "    lmu_trainable_params = sum(np.prod(w.shape) for w in lmu_model_summary.trainable_weights)\n",
    "    mem_fp, total, missed = memory_footprint(sim) \n",
    "    print('\\n=================================================================')\n",
    "    print('Total params:','{:,d}'.format(lmu_params))\n",
    "    print('Trainable params:','{:,d}'.format(lmu_trainable_params))\n",
    "    print('Non-trainable params:','{:,d}'.format(lmu_params-lmu_trainable_params)) \n",
    "    print('_________________________________________________________________\\n')\n",
    "    \n",
    "    mem_fp, total, missed = memory_footprint(sim)\n",
    "\n",
    "    print('Memory footprint (MB):',np.round(mem_fp,4))\n",
    "    print('Total:',total)\n",
    "    print('Missed:',missed)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    sim.compile(\n",
    "                loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                optimizer=tf.optimizers.Adam(network_parameters['lr']),\n",
    "                metrics=[\"accuracy\"],\n",
    "               )\n",
    "    \n",
    "    sim.load_params(\"./output/tmp_{}_{}_{}/best_test_{}\".format(net_type,snn_nni_experiment,datafile[5:],snn_nni_experiment))\n",
    "    \n",
    "    test = sim.evaluate(x_test, y_test)[\"probe_accuracy\"]\n",
    "    print(\"Test accuracy: \"+str(np.round(test*100,2))+\"%\")\n",
    "    \n",
    "    prediction = sim.predict(x_test)\n",
    "        \n",
    "    predictions = list(prediction.values())[0]\n",
    "    pred = predictions.argmax(axis=-1)\n",
    "    \n",
    "    save = True\n",
    "    \n",
    "    cm = confusion_matrix(y_test[:np.min([len(y_test), len(pred)]),-1,-1], pred[:np.min([len(y_test), len(pred)]),-1], normalize='true')\n",
    "    labels = ConfusionMatrix_labels(subset)\n",
    "    cm_df = pd.DataFrame(cm, index=[ii for ii in labels], columns=[jj for jj in labels])\n",
    "    plt.figure(figsize=(7,5.25))\n",
    "    sn.heatmap(cm_df,\n",
    "               annot=True,\n",
    "               fmt='.2g',\n",
    "               cbar=False,\n",
    "               square=False,\n",
    "               cmap=\"YlGnBu\")\n",
    "    plt.xlabel('\\nPredicted')\n",
    "    plt.ylabel('True\\n')\n",
    "    plt.title('LMU (frequency filtering)\\n', fontweight='bold', fontsize=16)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        plt.savefig('./pictures/'+model_name+'_'+optim_nni_experiment+'_'+optim_nni_trial+'.png')\n",
    "    plt.show()\n",
    "\n",
    "sim.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collective-mills",
   "metadata": {},
   "source": [
    "<a id='Section_7'></a>\n",
    "### Spiking LMU (ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-publication",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# set seed to ensure the examples are reproducible\n",
    "seed = 0\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-lender",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_type = 'slmu'\n",
    "\n",
    "device = 'watch'\n",
    "subset = 2\n",
    "time_window = 2\n",
    "\n",
    "window_size = 20*time_window # 20 Hz sampling times the temporal length of the window\n",
    "\n",
    "datafile = 'data_'+device+'_subset'+str(subset)+'_'+str(window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-excellence",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"sLMU_freqdec_{}_subset{}_{}\".format(device,subset_window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satellite-anatomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### GET NETWORK STRUCTURE PARAMETERS #####\n",
    "optim_nni_experiment = ''\n",
    "optim_nni_trial = ''\n",
    "optim_filename = 'parameter.cfg'\n",
    "optim_nni_ref = 'nni-experiments/'+optim_nni_experiment+'/trials/'+optim_nni_trial\n",
    "optim_nni_dir = os.path.expanduser('~')\n",
    "optim_filepath = os.path.join(optim_nni_dir,optim_nni_ref,optim_filename)\n",
    "\n",
    "with open(optim_filepath, 'r') as f:\n",
    "    data = f.read()\n",
    "\n",
    "params = json.loads(data)\n",
    "network_parameters = params['parameters']\n",
    "\n",
    "minibatch_train = network_parameters['minibatch']\n",
    "###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock-walter",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dec = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-study",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, x_val, x_test, y_train_oh, y_val_oh, y_test_oh) = load_wisdm2_data(datafile)\n",
    "\n",
    "if freq_dec:\n",
    "    x_train = frequency_decomposition(x_train)\n",
    "    x_val = frequency_decomposition(x_val)\n",
    "    x_test = frequency_decomposition(x_test)\n",
    "\n",
    "timesteps = len(x_train[0])\n",
    "input_dim = len(x_train[0][0])\n",
    "n_classes = len(y_train_oh[0])\n",
    "\n",
    "y_train = np.argmax(y_train_oh, axis=-1)\n",
    "y_val = np.argmax(y_val_oh, axis=-1)\n",
    "y_test = np.argmax(y_test_oh, axis=-1)\n",
    "\n",
    "print('timesteps:',timesteps)\n",
    "print('input_dim:',input_dim)\n",
    "print('n_classes:',n_classes)\n",
    "\n",
    "y_train = y_train[:, None, None]\n",
    "y_test = y_test[:, None, None]\n",
    "y_val = y_val[:, None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indie-packaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "with nengo.Network(seed=seed) as net:\n",
    "    # remove some unnecessary features to speed up the training\n",
    "    nengo_dl.configure_settings(\n",
    "        trainable=None,\n",
    "        stateful=False,\n",
    "        keep_history=False,\n",
    "    )\n",
    "\n",
    "    # input node\n",
    "    inp = nengo.Node(np.zeros(input_dim))\n",
    "    \n",
    "    order = int(network_parameters['order'])\n",
    "    theta = network_parameters['theta']\n",
    "    input_d = input_dim\n",
    "    tau = network_parameters['tau'] \n",
    "    \n",
    "    Q = np.arange(order, dtype=np.float64)\n",
    "    R = (2 * Q + 1)[:, None] / theta\n",
    "    j, i = np.meshgrid(Q, Q)\n",
    "    A = np.where(i < j, -1, (-1.0) ** (i - j + 1)) * R \n",
    "    B = (-1.0) ** Q[:, None] * R \n",
    "    C = np.ones((1, order))\n",
    "    D = np.zeros((1,))\n",
    "\n",
    "    disc_step = 1/theta\n",
    "    A, B, _, _, _ = cont2discrete((A, B, C, D), dt=disc_step, method=\"zoh\") \n",
    "    \n",
    "    A_H = 1/(1-np.exp(-disc_step/tau)) * (A - np.exp(-disc_step/tau)*np.identity(order))\n",
    "    B_H = 1/(1-np.exp(-disc_step/tau)) * B\n",
    "\n",
    "    for conn in net.all_connections:\n",
    "        conn.synapse = network_parameters['synapse_all']\n",
    "\n",
    "    max_rate = network_parameters['max_rate']\n",
    "    amplitude = 1/max_rate\n",
    "    lmu_inner = nengo.networks.EnsembleArray(n_neurons=int(network_parameters['n_neurons']),\n",
    "                                             n_ensembles=order, \n",
    "                                             neuron_type=nengo.SpikingRectifiedLinear(amplitude=amplitude),\n",
    "                                             max_rates=nengo.dists.Choice([max_rate]))\n",
    "    conn_inner = nengo.Connection(lmu_inner.output, lmu_inner.input, transform=A_H, synapse=tau)\n",
    "    net.config[conn_inner].trainable = True\n",
    "    \n",
    "    conn_in = nengo.Connection(inp, lmu_inner.input, transform=np.ones((1, input_d))*B_H, synapse=network_parameters['synapse_in'])\n",
    "    net.config[conn_in].trainable = True\n",
    "    \n",
    "    # dense linear readout\n",
    "    out = nengo.Node(size_in=n_classes)\n",
    "    conn_out = nengo.Connection(lmu_inner.output, out, transform=nengo_dl.dists.Glorot(), synapse=network_parameters['synapse_out'])\n",
    "    net.config[conn_out].trainable = True\n",
    "\n",
    "    # record output\n",
    "    p = nengo.Probe(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reliable-history",
   "metadata": {},
   "outputs": [],
   "source": [
    "with nengo_dl.Simulator(net, minibatch_size=minibatch_train) as sim: \n",
    "    \n",
    "    lmuEns_model_summary = sim.keras_model\n",
    "    lmuEns_params = sum(np.prod(s.shape) for s in lmuEns_model_summary.weights)\n",
    "    lmuEns_trainable_params = sum(np.prod(w.shape) for w in lmuEns_model_summary.trainable_weights)\n",
    "    mem_fp, total, missed = memory_footprint(sim) \n",
    "    print('\\n=================================================================')\n",
    "    print('Total params:','{:,d}'.format(lmuEns_params))\n",
    "    print('Trainable params:','{:,d}'.format(lmuEns_trainable_params))\n",
    "    print('Non-trainable params:','{:,d}'.format(lmuEns_params-lmuEns_trainable_params)) \n",
    "    print('_________________________________________________________________\\n')\n",
    "    \n",
    "    mem_fp, total, missed = memory_footprint(sim)\n",
    "\n",
    "    print('Memory footprint (MB):',np.round(mem_fp,4))\n",
    "    print('Total:',total)\n",
    "    print('Missed:',missed)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    sim.compile(\n",
    "                loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                optimizer=tf.optimizers.Adam(network_parameters['lr']),\n",
    "                metrics=[\"accuracy\"],\n",
    "               )\n",
    "    \n",
    "    sim.load_params(\"./output/tmp_s{}_{}_{}/best_test_{}\".format(net_type,snn_nni_experiment,datafile[5:],snn_nni_experiment))\n",
    "    \n",
    "    test = sim.evaluate(x_test, y_test)[\"probe_accuracy\"]\n",
    "    print(\"Test accuracy: \"+str(np.round(test*100,2))+\"%\")\n",
    "    \n",
    "    prediction = sim.predict(x_test)\n",
    "        \n",
    "    predictions = list(prediction.values())[0]\n",
    "    pred = predictions.argmax(axis=-1)\n",
    "    \n",
    "    save = True\n",
    "    \n",
    "    cm = confusion_matrix(y_test[:np.min([len(y_test), len(pred)]),-1,-1], pred[:np.min([len(y_test), len(pred)]),-1], normalize='true')\n",
    "    labels = ConfusionMatrix_labels(subset)\n",
    "    cm_df = pd.DataFrame(cm, index=[ii for ii in labels], columns=[jj for jj in labels])\n",
    "    plt.figure(figsize=(7,5.25))\n",
    "    sn.heatmap(cm_df,\n",
    "               annot=True,\n",
    "               fmt='.2g',\n",
    "               cbar=False,\n",
    "               square=False,\n",
    "               cmap=\"YlGnBu\")\n",
    "    plt.xlabel('\\nPredicted')\n",
    "    plt.ylabel('True\\n')\n",
    "    plt.title('Spiking LMU (frequency filtering)\\n', fontweight='bold', fontsize=16)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        plt.savefig('./pictures/'+model_name+'_'+optim_nni_experiment+'_'+optim_nni_trial+'.png')\n",
    "    plt.show()\n",
    "\n",
    "sim.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parliamentary-romantic",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_sops_LMUens(net, freq_dec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792081e0",
   "metadata": {},
   "source": [
    "<a id='Section_8'></a>\n",
    "### <i>FLOPs calculation and energy estimation for LMU and LMU (ff)</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock-calgary",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Core classes for the KerasLMU package.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from packaging import version\n",
    "\n",
    "if version.parse(tf.__version__) < version.parse(\"2.6.0rc0\"):\n",
    "    from tensorflow.python.keras.layers.recurrent import DropoutRNNCellMixin\n",
    "else:\n",
    "    from keras.layers.recurrent import DropoutRNNCellMixin\n",
    "\n",
    "\n",
    "class LMUCell(DropoutRNNCellMixin, tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Implementation of LMU cell (to be used within Keras RNN wrapper).\n",
    "    In general, the LMU cell consists of two parts: a memory component (decomposing\n",
    "    the input signal using Legendre polynomials as a basis), and a hidden component\n",
    "    (learning nonlinear mappings from the memory component). [1]_ [2]_\n",
    "    This class processes one step within the whole time sequence input. Use the ``LMU``\n",
    "    class to create a recurrent Keras layer to process the whole sequence. Calling\n",
    "    ``LMU()`` is equivalent to doing ``RNN(LMUCell())``.\n",
    "    Parameters\n",
    "    ----------\n",
    "    memory_d : int\n",
    "        Dimensionality of input to memory component.\n",
    "    order : int\n",
    "        The number of degrees in the transfer function of the LTI system used to\n",
    "        represent the sliding window of history. This parameter sets the number of\n",
    "        Legendre polynomials used to orthogonally represent the sliding window.\n",
    "    theta : float\n",
    "        The number of timesteps in the sliding window that is represented using the\n",
    "        LTI system. In this context, the sliding window represents a dynamic range of\n",
    "        data, of fixed size, that will be used to predict the value at the next time\n",
    "        step. If this value is smaller than the size of the input sequence, only that\n",
    "        number of steps will be represented at the time of prediction, however the\n",
    "        entire sequence will still be processed in order for information to be\n",
    "        projected to and from the hidden layer. If ``trainable_theta`` is enabled, then\n",
    "        theta will be updated during the course of training.\n",
    "    hidden_cell : ``tf.keras.layers.Layer``\n",
    "        Keras Layer/RNNCell implementing the hidden component.\n",
    "    trainable_theta : bool\n",
    "        If True, theta is learnt over the course of training. Otherwise, it is kept\n",
    "        constant.\n",
    "    hidden_to_memory : bool\n",
    "        If True, connect the output of the hidden component back to the memory\n",
    "        component (default False).\n",
    "    memory_to_memory : bool\n",
    "        If True, add a learnable recurrent connection (in addition to the static\n",
    "        Legendre system) to the memory component (default False).\n",
    "    input_to_hidden : bool\n",
    "        If True, connect the input directly to the hidden component (in addition to\n",
    "        the connection from the memory component) (default False).\n",
    "    discretizer : str\n",
    "        The method used to discretize the A and B matrices of the LMU. Current\n",
    "        options are \"zoh\" (short for Zero Order Hold) and \"euler\".\n",
    "        \"zoh\" is more accurate, but training will be slower than \"euler\" if\n",
    "        ``trainable_theta=True``. Note that a larger theta is needed when discretizing\n",
    "        using \"euler\" (a value that is larger than ``4*order`` is recommended).\n",
    "    kernel_initializer : ``tf.initializers.Initializer``\n",
    "        Initializer for weights from input to memory/hidden component. If ``None``,\n",
    "        no weights will be used, and the input size must match the memory/hidden size.\n",
    "    recurrent_initializer : ``tf.initializers.Initializer``\n",
    "        Initializer for ``memory_to_memory`` weights (if that connection is enabled).\n",
    "    dropout : float\n",
    "        Dropout rate on input connections.\n",
    "    recurrent_dropout : float\n",
    "        Dropout rate on ``memory_to_memory`` connection.\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Voelker and Eliasmith (2018). Improving spiking dynamical\n",
    "       networks: Accurate delays, higher-order synapses, and time cells.\n",
    "       Neural Computation, 30(3): 569-609.\n",
    "    .. [2] Voelker and Eliasmith. \"Methods and systems for implementing\n",
    "       dynamic neural networks.\" U.S. Patent Application No. 15/243,223.\n",
    "       Filing date: 2016-08-22.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        memory_d,\n",
    "        order,\n",
    "        theta,\n",
    "        hidden_cell,\n",
    "        trainable_theta=False,\n",
    "        hidden_to_memory=False,\n",
    "        memory_to_memory=False,\n",
    "        input_to_hidden=False,\n",
    "        discretizer=\"zoh\",\n",
    "        kernel_initializer=\"glorot_uniform\",\n",
    "        recurrent_initializer=\"orthogonal\",\n",
    "        dropout=0,\n",
    "        recurrent_dropout=0,\n",
    "        tau=0.001, \n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.memory_d = memory_d\n",
    "        self.order = order\n",
    "        self._init_theta = theta\n",
    "        self.hidden_cell = hidden_cell\n",
    "        self.trainable_theta = trainable_theta\n",
    "        self.hidden_to_memory = hidden_to_memory\n",
    "        self.memory_to_memory = memory_to_memory\n",
    "        self.input_to_hidden = input_to_hidden\n",
    "        self.discretizer = discretizer\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.recurrent_initializer = recurrent_initializer\n",
    "        self.dropout = dropout\n",
    "        self.recurrent_dropout = recurrent_dropout\n",
    "        self.tau = tau\n",
    "\n",
    "        self.kernel = None\n",
    "        self.recurrent_kernel = None\n",
    "        self.theta_inv = None\n",
    "        self.A = None\n",
    "        self.B = None\n",
    "\n",
    "        if self.discretizer not in (\"zoh\", \"euler\"):\n",
    "            raise ValueError(\n",
    "                f\"discretizer must be 'zoh' or 'euler' (got '{self.discretizer}')\"\n",
    "            )\n",
    "\n",
    "        if self.hidden_cell is None:\n",
    "            for conn in (\"hidden_to_memory\", \"input_to_hidden\"):\n",
    "                if getattr(self, conn):\n",
    "                    raise ValueError(f\"{conn} must be False if hidden_cell is None\")\n",
    "\n",
    "            self.hidden_output_size = self.memory_d * self.order\n",
    "            self.hidden_state_size = []\n",
    "        elif hasattr(self.hidden_cell, \"state_size\"):\n",
    "            self.hidden_output_size = self.hidden_cell.output_size\n",
    "            self.hidden_state_size = self.hidden_cell.state_size\n",
    "        else:\n",
    "            # TODO: support layers that don't have the `units` attribute\n",
    "            self.hidden_output_size = self.hidden_cell.units\n",
    "            self.hidden_state_size = [self.hidden_cell.units]\n",
    "\n",
    "        self.state_size = tf.nest.flatten(self.hidden_state_size) + [\n",
    "            self.memory_d * self.order\n",
    "        ]\n",
    "        self.output_size = self.hidden_output_size\n",
    "\n",
    "    @property\n",
    "    def theta(self):\n",
    "        \"\"\"\n",
    "        Value of the ``theta`` parameter.\n",
    "        If ``trainable_theta=True`` this returns the trained value, not the initial\n",
    "        value passed in to the constructor.\n",
    "        \"\"\"\n",
    "        if self.built:\n",
    "            return 1 / tf.keras.backend.get_value(self.theta_inv)\n",
    "\n",
    "        return self._init_theta\n",
    "\n",
    "    def _gen_AB(self):\n",
    "        \"\"\"Generates A and B matrices.\"\"\"\n",
    "\n",
    "        # compute analog A/B matrices\n",
    "        Q = np.arange(self.order, dtype=np.float64)\n",
    "        R = (2 * Q + 1)[:, None] / self._init_theta\n",
    "        j, i = np.meshgrid(Q, Q)\n",
    "        A = np.where(i < j, -1, (-1.0) ** (i - j + 1)) * R\n",
    "        B = (-1.0) ** Q[:, None] * R\n",
    "        \n",
    "        disc_step = 1/self._init_theta\n",
    "        A = 1/(1-np.exp(-disc_step/self.tau)) * (A - np.exp(-disc_step/self.tau)*np.identity(self.order))  \n",
    "        B = 1/(1-np.exp(-disc_step/self.tau)) * B  \n",
    "\n",
    "        # discretize matrices\n",
    "        if self.discretizer == \"zoh\":\n",
    "            # save the un-discretized matrices for use in .call\n",
    "            self._base_A = tf.constant(A.T, dtype=self.dtype)\n",
    "            self._base_B = tf.constant(B.T, dtype=self.dtype)\n",
    "            \n",
    "            disc_step = 1/self._init_theta\n",
    "            self.A, self.B = LMUCell._cont2discrete_zoh(\n",
    "                self._base_A / self._init_theta, self._base_B / self._init_theta, disc_step\n",
    "            )\n",
    "        else:\n",
    "            if not self.trainable_theta:\n",
    "                A = A / self._init_theta + np.eye(self.order)\n",
    "                B = B / self._init_theta\n",
    "\n",
    "            self.A = tf.constant(A.T, dtype=self.dtype)\n",
    "            self.B = tf.constant(B.T, dtype=self.dtype)\n",
    "\n",
    "    @staticmethod\n",
    "    def _cont2discrete_zoh(A, B, dt):\n",
    "        \"\"\"\n",
    "        Function to discretize A and B matrices using Zero Order Hold method.\n",
    "        Functionally equivalent to\n",
    "        ``scipy.signal.cont2discrete((A.T, B.T, _, _), method=\"zoh\", dt=1.0)``\n",
    "        (but implemented in TensorFlow so that it is differentiable).\n",
    "        Note that this accepts and returns matrices that are transposed from the\n",
    "        standard linear system implementation (as that makes it easier to use in\n",
    "        `.call`).\n",
    "        \"\"\"\n",
    "\n",
    "        # combine A/B and pad to make square matrix\n",
    "        em_upper = tf.concat([A, B], axis=0)\n",
    "        em = tf.pad(em_upper, [(0, 0), (0, B.shape[0])])\n",
    "\n",
    "        # compute matrix exponential\n",
    "        ms = tf.linalg.expm(dt*em)\n",
    "\n",
    "        # slice A/B back out of combined matrix\n",
    "        discrt_A = ms[: A.shape[0], : A.shape[1]]\n",
    "        discrt_B = ms[A.shape[0] :, : A.shape[1]]\n",
    "\n",
    "        return discrt_A, discrt_B\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \"\"\"\n",
    "        Builds the cell.\n",
    "        Notes\n",
    "        -----\n",
    "        This method should not be called manually; rather, use the implicit layer\n",
    "        callable behaviour (like ``my_layer(inputs)``), which will apply this method\n",
    "        with some additional bookkeeping.\n",
    "        \"\"\"\n",
    "\n",
    "        super().build(input_shape)\n",
    "\n",
    "        enc_d = input_shape[-1]\n",
    "        if self.hidden_to_memory:\n",
    "            enc_d += self.hidden_output_size\n",
    "\n",
    "        if self.kernel_initializer is not None:\n",
    "            self.kernel = self.add_weight(\n",
    "                name=\"kernel\",\n",
    "                shape=(enc_d, self.memory_d),\n",
    "                initializer=self.kernel_initializer,\n",
    "            )\n",
    "        else:\n",
    "            self.kernel = None\n",
    "            if enc_d != self.memory_d:\n",
    "                raise ValueError(\n",
    "                    f\"For LMUCells with no input kernel, the input dimension ({enc_d})\"\n",
    "                    f\" must equal `memory_d` ({self.memory_d}).\"\n",
    "                )\n",
    "\n",
    "        # when using euler, 1/theta results in better gradients for the memory\n",
    "        # update since you are multiplying 1/theta, as compared to dividing theta\n",
    "        if self.trainable_theta:\n",
    "            self.theta_inv = self.add_weight(\n",
    "                name=\"theta_inv\",\n",
    "                shape=(),\n",
    "                initializer=tf.initializers.constant(1 / self._init_theta),\n",
    "                constraint=tf.keras.constraints.NonNeg(),\n",
    "            )\n",
    "        else:\n",
    "            self.theta_inv = tf.constant(1 / self._init_theta, dtype=self.dtype)\n",
    "\n",
    "        if self.memory_to_memory:\n",
    "            self.recurrent_kernel = self.add_weight(\n",
    "                name=\"recurrent_kernel\",\n",
    "                shape=(self.memory_d * self.order, self.memory_d),\n",
    "                initializer=self.recurrent_initializer,\n",
    "            )\n",
    "        else:\n",
    "            self.recurrent_kernel = None\n",
    "\n",
    "        if self.hidden_cell is not None and not self.hidden_cell.built:\n",
    "            hidden_input_d = self.memory_d * self.order\n",
    "            if self.input_to_hidden:\n",
    "                hidden_input_d += input_shape[-1]\n",
    "            with tf.name_scope(self.hidden_cell.name):\n",
    "                self.hidden_cell.build((input_shape[0], hidden_input_d))\n",
    "\n",
    "        # generate A and B matrices\n",
    "        self._gen_AB()\n",
    "\n",
    "    def call(self, inputs, states, training=None):\n",
    "        \"\"\"\n",
    "        Apply this cell to inputs.\n",
    "        Notes\n",
    "        -----\n",
    "        This method should not be called manually; rather, use the implicit layer\n",
    "        callable behaviour (like ``my_layer(inputs)``), which will apply this method\n",
    "        with some additional bookkeeping.\n",
    "        \"\"\"\n",
    "\n",
    "        if training is None:\n",
    "            training = tf.keras.backend.learning_phase()\n",
    "\n",
    "        states = tf.nest.flatten(states)\n",
    "\n",
    "        # state for the hidden cell\n",
    "        h = states[:-1]\n",
    "        # state for the LMU memory\n",
    "        m = states[-1]\n",
    "\n",
    "        # compute memory input\n",
    "        u_in = tf.concat((inputs, h[0]), axis=1) if self.hidden_to_memory else inputs\n",
    "        if self.dropout > 0:\n",
    "            u_in *= self.get_dropout_mask_for_cell(u_in, training)\n",
    "        u = u_in if self.kernel is None else tf.matmul(u_in, self.kernel)\n",
    "\n",
    "        if self.memory_to_memory:\n",
    "            if self.recurrent_dropout > 0:\n",
    "                # note: we don't apply dropout to the memory input, only\n",
    "                # the recurrent kernel\n",
    "                rec_m = m * self.get_recurrent_dropout_mask_for_cell(m, training)\n",
    "            else:\n",
    "                rec_m = m\n",
    "\n",
    "            u += tf.matmul(rec_m, self.recurrent_kernel)\n",
    "\n",
    "        # separate memory/order dimensions\n",
    "        m = tf.reshape(m, (-1, self.memory_d, self.order))\n",
    "        u = tf.expand_dims(u, -1)\n",
    "\n",
    "        # update memory\n",
    "        if self.discretizer == \"zoh\" and self.trainable_theta:\n",
    "            # apply updated theta and re-discretize\n",
    "            A, B = LMUCell._cont2discrete_zoh(\n",
    "                self._base_A * self.theta_inv, self._base_B * self.theta_inv\n",
    "            )\n",
    "        else:\n",
    "            A, B = self.A, self.B\n",
    "\n",
    "        _m = tf.matmul(m, A) + tf.matmul(u, B)\n",
    "\n",
    "        if self.discretizer == \"euler\" and self.trainable_theta:\n",
    "            # apply updated theta. this is the same as scaling A/B by theta, but it's\n",
    "            # more efficient to do it this way.\n",
    "            # note that when computing this way the A matrix does not\n",
    "            # include the identity matrix along the diagonal (since we don't want to\n",
    "            # scale that part by theta), which is why we do += instead of =\n",
    "            m += _m * self.theta_inv\n",
    "        else:\n",
    "            m = _m\n",
    "\n",
    "        # re-combine memory/order dimensions\n",
    "        m = tf.reshape(m, (-1, self.memory_d * self.order))\n",
    "\n",
    "        # apply hidden cell\n",
    "        h_in = tf.concat((m, inputs), axis=1) if self.input_to_hidden else m\n",
    "\n",
    "        if self.hidden_cell is None:\n",
    "            o = h_in\n",
    "            h = []\n",
    "        elif hasattr(self.hidden_cell, \"state_size\"):\n",
    "            o, h = self.hidden_cell(h_in, h, training=training)\n",
    "        else:\n",
    "            o = self.hidden_cell(h_in, training=training)\n",
    "            h = [o]\n",
    "\n",
    "        return o, h + [m]\n",
    "\n",
    "    def reset_dropout_mask(self):\n",
    "        \"\"\"Reset dropout mask for memory and hidden components.\"\"\"\n",
    "        super().reset_dropout_mask()\n",
    "        if isinstance(self.hidden_cell, DropoutRNNCellMixin):\n",
    "            self.hidden_cell.reset_dropout_mask()\n",
    "\n",
    "    def reset_recurrent_dropout_mask(self):\n",
    "        \"\"\"Reset recurrent dropout mask for memory and hidden components.\"\"\"\n",
    "        super().reset_recurrent_dropout_mask()\n",
    "        if isinstance(self.hidden_cell, DropoutRNNCellMixin):\n",
    "            self.hidden_cell.reset_recurrent_dropout_mask()\n",
    "\n",
    "    def get_config(self):\n",
    "        \"\"\"Return config of layer (for serialization during model saving/loading).\"\"\"\n",
    "\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            dict(\n",
    "                memory_d=self.memory_d,\n",
    "                order=self.order,\n",
    "                theta=self._init_theta,\n",
    "                hidden_cell=tf.keras.layers.serialize(self.hidden_cell),\n",
    "                trainable_theta=self.trainable_theta,\n",
    "                hidden_to_memory=self.hidden_to_memory,\n",
    "                memory_to_memory=self.memory_to_memory,\n",
    "                input_to_hidden=self.input_to_hidden,\n",
    "                discretizer=self.discretizer,\n",
    "                kernel_initializer=self.kernel_initializer,\n",
    "                recurrent_initializer=self.recurrent_initializer,\n",
    "                dropout=self.dropout,\n",
    "                recurrent_dropout=self.recurrent_dropout,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        \"\"\"Load model from serialized config.\"\"\"\n",
    "\n",
    "        config[\"hidden_cell\"] = tf.keras.layers.deserialize(config[\"hidden_cell\"])\n",
    "        return super().from_config(config)\n",
    "\n",
    "\n",
    "class LMU(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    A layer of trainable low-dimensional delay systems.\n",
    "    Each unit buffers its encoded input\n",
    "    by internally representing a low-dimensional\n",
    "    (i.e., compressed) version of the sliding window.\n",
    "    Nonlinear decodings of this representation,\n",
    "    expressed by the A and B matrices, provide\n",
    "    computations across the window, such as its\n",
    "    derivative, energy, median value, etc ([1]_, [2]_).\n",
    "    Note that these decoder matrices can span across\n",
    "    all of the units of an input sequence.\n",
    "    Parameters\n",
    "    ----------\n",
    "    memory_d : int\n",
    "        Dimensionality of input to memory component.\n",
    "    order : int\n",
    "        The number of degrees in the transfer function of the LTI system used to\n",
    "        represent the sliding window of history. This parameter sets the number of\n",
    "        Legendre polynomials used to orthogonally represent the sliding window.\n",
    "    theta : float\n",
    "        The number of timesteps in the sliding window that is represented using the\n",
    "        LTI system. In this context, the sliding window represents a dynamic range of\n",
    "        data, of fixed size, that will be used to predict the value at the next time\n",
    "        step. If this value is smaller than the size of the input sequence, only that\n",
    "        number of steps will be represented at the time of prediction, however the\n",
    "        entire sequence will still be processed in order for information to be\n",
    "        projected to and from the hidden layer. If ``trainable_theta`` is enabled, then\n",
    "        theta will be updated during the course of training.\n",
    "    hidden_cell : ``tf.keras.layers.Layer``\n",
    "        Keras Layer/RNNCell implementing the hidden component.\n",
    "    trainable_theta : bool\n",
    "        If True, theta is learnt over the course of training. Otherwise, it is kept\n",
    "        constant.\n",
    "    hidden_to_memory : bool\n",
    "        If True, connect the output of the hidden component back to the memory\n",
    "        component (default False).\n",
    "    memory_to_memory : bool\n",
    "        If True, add a learnable recurrent connection (in addition to the static\n",
    "        Legendre system) to the memory component (default False).\n",
    "    input_to_hidden : bool\n",
    "        If True, connect the input directly to the hidden component (in addition to\n",
    "        the connection from the memory component) (default False).\n",
    "    discretizer : str\n",
    "        The method used to discretize the A and B matrices of the LMU. Current\n",
    "        options are \"zoh\" (short for Zero Order Hold) and \"euler\".\n",
    "        \"zoh\" is more accurate, but training will be slower than \"euler\" if\n",
    "        ``trainable_theta=True``. Note that a larger theta is needed when discretizing\n",
    "        using \"euler\" (a value that is larger than ``4*order`` is recommended).\n",
    "    kernel_initializer : ``tf.initializers.Initializer``\n",
    "        Initializer for weights from input to memory/hidden component. If ``None``,\n",
    "        no weights will be used, and the input size must match the memory/hidden size.\n",
    "    recurrent_initializer : ``tf.initializers.Initializer``\n",
    "        Initializer for ``memory_to_memory`` weights (if that connection is enabled).\n",
    "    dropout : float\n",
    "        Dropout rate on input connections.\n",
    "    recurrent_dropout : float\n",
    "        Dropout rate on ``memory_to_memory`` connection.\n",
    "    return_sequences : bool, optional\n",
    "        If True, return the full output sequence. Otherwise, return just the last\n",
    "        output in the output sequence.\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Voelker and Eliasmith (2018). Improving spiking dynamical\n",
    "       networks: Accurate delays, higher-order synapses, and time cells.\n",
    "       Neural Computation, 30(3): 569-609.\n",
    "    .. [2] Voelker and Eliasmith. \"Methods and systems for implementing\n",
    "       dynamic neural networks.\" U.S. Patent Application No. 15/243,223.\n",
    "       Filing date: 2016-08-22.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        memory_d,\n",
    "        order,\n",
    "        theta,\n",
    "        hidden_cell,\n",
    "        trainable_theta=False,\n",
    "        hidden_to_memory=False,\n",
    "        memory_to_memory=False,\n",
    "        input_to_hidden=False,\n",
    "        discretizer=\"zoh\",\n",
    "        kernel_initializer=\"glorot_uniform\",\n",
    "        recurrent_initializer=\"orthogonal\",\n",
    "        dropout=0,\n",
    "        recurrent_dropout=0,\n",
    "        return_sequences=False,\n",
    "        tau=0.001,\n",
    "        **kwargs,\n",
    "    ):\n",
    "\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.memory_d = memory_d\n",
    "        self.order = order\n",
    "        self._init_theta = theta\n",
    "        self.hidden_cell = hidden_cell\n",
    "        self.trainable_theta = trainable_theta\n",
    "        self.hidden_to_memory = hidden_to_memory\n",
    "        self.memory_to_memory = memory_to_memory\n",
    "        self.input_to_hidden = input_to_hidden\n",
    "        self.discretizer = discretizer\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.recurrent_initializer = recurrent_initializer\n",
    "        self.dropout = dropout\n",
    "        self.recurrent_dropout = recurrent_dropout\n",
    "        self.return_sequences = return_sequences\n",
    "        self.layer = None\n",
    "        self.tau = tau\n",
    "\n",
    "    @property\n",
    "    def theta(self):\n",
    "        \"\"\"\n",
    "        Value of the ``theta`` parameter.\n",
    "        If ``trainable_theta=True`` this returns the trained value, not the initial\n",
    "        value passed in to the constructor.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.built:\n",
    "            return (\n",
    "                self.layer.theta\n",
    "                if isinstance(self.layer, LMUFeedforward)\n",
    "                else self.layer.cell.theta\n",
    "            )\n",
    "\n",
    "        return self._init_theta\n",
    "\n",
    "    def build(self, input_shapes):\n",
    "        \"\"\"\n",
    "        Builds the layer.\n",
    "        Notes\n",
    "        -----\n",
    "        This method should not be called manually; rather, use the implicit layer\n",
    "        callable behaviour (like ``my_layer(inputs)``), which will apply this method\n",
    "        with some additional bookkeeping.\n",
    "        \"\"\"\n",
    "\n",
    "        super().build(input_shapes)\n",
    "\n",
    "        if (\n",
    "            not self.hidden_to_memory\n",
    "            and not self.memory_to_memory\n",
    "            and input_shapes[1] is not None\n",
    "            and not self.trainable_theta\n",
    "        ):\n",
    "            self.layer = LMUFeedforward(\n",
    "                memory_d=self.memory_d,\n",
    "                order=self.order,\n",
    "                theta=self._init_theta,\n",
    "                hidden_cell=self.hidden_cell,\n",
    "                input_to_hidden=self.input_to_hidden,\n",
    "                discretizer=self.discretizer,\n",
    "                kernel_initializer=self.kernel_initializer,\n",
    "                dropout=self.dropout,\n",
    "                return_sequences=self.return_sequences,\n",
    "            )\n",
    "        else:\n",
    "            self.layer = tf.keras.layers.RNN(\n",
    "                LMUCell(\n",
    "                    memory_d=self.memory_d,\n",
    "                    order=self.order,\n",
    "                    theta=self._init_theta,\n",
    "                    hidden_cell=self.hidden_cell,\n",
    "                    trainable_theta=self.trainable_theta,\n",
    "                    hidden_to_memory=self.hidden_to_memory,\n",
    "                    memory_to_memory=self.memory_to_memory,\n",
    "                    input_to_hidden=self.input_to_hidden,\n",
    "                    discretizer=self.discretizer,\n",
    "                    kernel_initializer=self.kernel_initializer,\n",
    "                    recurrent_initializer=self.recurrent_initializer,\n",
    "                    dropout=self.dropout,\n",
    "                    recurrent_dropout=self.recurrent_dropout,\n",
    "                    tau=self.tau,\n",
    "                ),\n",
    "                return_sequences=self.return_sequences,\n",
    "            )\n",
    "\n",
    "        self.layer.build(input_shapes)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        \"\"\"\n",
    "        Apply this layer to inputs.\n",
    "        Notes\n",
    "        -----\n",
    "        This method should not be called manually; rather, use the implicit layer\n",
    "        callable behaviour (like ``my_layer(inputs)``), which will apply this method\n",
    "        with some additional bookkeeping.\n",
    "        \"\"\"\n",
    "\n",
    "        return self.layer.call(inputs, training=training)\n",
    "\n",
    "    def get_config(self):\n",
    "        \"\"\"Return config of layer (for serialization during model saving/loading).\"\"\"\n",
    "\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            dict(\n",
    "                memory_d=self.memory_d,\n",
    "                order=self.order,\n",
    "                theta=self._init_theta,\n",
    "                hidden_cell=tf.keras.layers.serialize(self.hidden_cell),\n",
    "                trainable_theta=self.trainable_theta,\n",
    "                hidden_to_memory=self.hidden_to_memory,\n",
    "                memory_to_memory=self.memory_to_memory,\n",
    "                input_to_hidden=self.input_to_hidden,\n",
    "                discretizer=self.discretizer,\n",
    "                kernel_initializer=self.kernel_initializer,\n",
    "                recurrent_initializer=self.recurrent_initializer,\n",
    "                dropout=self.dropout,\n",
    "                recurrent_dropout=self.recurrent_dropout,\n",
    "                return_sequences=self.return_sequences,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        \"\"\"Load model from serialized config.\"\"\"\n",
    "\n",
    "        config[\"hidden_cell\"] = tf.keras.layers.deserialize(config[\"hidden_cell\"])\n",
    "        return super().from_config(config)\n",
    "\n",
    "\n",
    "class LMUFeedforward(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Layer class for the feedforward variant of the LMU.\n",
    "    This class assumes no recurrent connections are desired in the memory component.\n",
    "    Produces the output of the delay system by evaluating the convolution of the input\n",
    "    sequence with the impulse response from the LMU cell.\n",
    "    Parameters\n",
    "    ----------\n",
    "    memory_d : int\n",
    "        Dimensionality of input to memory component.\n",
    "    order : int\n",
    "        The number of degrees in the transfer function of the LTI system used to\n",
    "        represent the sliding window of history. This parameter sets the number of\n",
    "        Legendre polynomials used to orthogonally represent the sliding window.\n",
    "    theta : float\n",
    "        The number of timesteps in the sliding window that is represented using the\n",
    "        LTI system. In this context, the sliding window represents a dynamic range of\n",
    "        data, of fixed size, that will be used to predict the value at the next time\n",
    "        step. If this value is smaller than the size of the input sequence, only that\n",
    "        number of steps will be represented at the time of prediction, however the\n",
    "        entire sequence will still be processed in order for information to be\n",
    "        projected to and from the hidden layer.\n",
    "    hidden_cell : ``tf.keras.layers.Layer``\n",
    "        Keras Layer implementing the hidden component.\n",
    "    input_to_hidden : bool\n",
    "        If True, connect the input directly to the hidden component (in addition to\n",
    "        the connection from the memory component) (default False).\n",
    "    discretizer : str\n",
    "        The method used to discretize the A and B matrices of the LMU. Current\n",
    "        options are \"zoh\" (short for Zero Order Hold) and \"euler\".\n",
    "        \"zoh\" is more accurate, but training will be slower than \"euler\" if\n",
    "        ``trainable_theta=True``. Note that a larger theta is needed when discretizing\n",
    "        using \"euler\" (a value that is larger than ``4*order`` is recommended).\n",
    "    kernel_initializer : ``tf.initializers.Initializer``\n",
    "        Initializer for weights from input to memory/hidden component. If ``None``,\n",
    "        no weights will be used, and the input size must match the memory/hidden size.\n",
    "    dropout : float\n",
    "        Dropout rate on input connections.\n",
    "    return_sequences : bool, optional\n",
    "        If True, return the full output sequence. Otherwise, return just the last\n",
    "        output in the output sequence.\n",
    "    conv_mode : \"fft\" or \"raw\"\n",
    "        The method for performing the inpulse response convolution. \"fft\" uses FFT\n",
    "        convolution (default). \"raw\" uses explicit convolution, which may be faster\n",
    "        for particular models on particular hardware.\n",
    "    truncate_ir : float\n",
    "        The portion of the impulse response to truncate when using \"raw\"\n",
    "        convolution (see ``conv_mode``). This is an approximate upper bound on the error\n",
    "        relative to the exact implementation. Smaller ``theta`` values result in more\n",
    "        truncated elements for a given value of ``truncate_ir``, improving efficiency.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        memory_d,\n",
    "        order,\n",
    "        theta,\n",
    "        hidden_cell,\n",
    "        input_to_hidden=False,\n",
    "        discretizer=\"zoh\",\n",
    "        kernel_initializer=\"glorot_uniform\",\n",
    "        dropout=0,\n",
    "        return_sequences=False,\n",
    "        conv_mode=\"fft\",\n",
    "        truncate_ir=1e-4,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        if input_to_hidden and hidden_cell is None:\n",
    "            raise ValueError(\"input_to_hidden must be False if hidden_cell is None\")\n",
    "\n",
    "        if conv_mode not in (\"fft\", \"raw\"):\n",
    "            raise ValueError(f\"Unrecognized conv mode '{conv_mode}'\")\n",
    "\n",
    "        self.memory_d = memory_d\n",
    "        self.order = order\n",
    "        self.theta = theta\n",
    "        self.hidden_cell = hidden_cell\n",
    "        self.input_to_hidden = input_to_hidden\n",
    "        self.discretizer = discretizer\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.dropout = dropout\n",
    "        self.return_sequences = return_sequences\n",
    "        self.conv_mode = conv_mode.lower()\n",
    "        self.truncate_ir = truncate_ir\n",
    "\n",
    "        # create a standard LMUCell to generate the impulse response during `build`\n",
    "        self.delay_layer = tf.keras.layers.RNN(\n",
    "            LMUCell(\n",
    "                memory_d=1,\n",
    "                order=order,\n",
    "                theta=theta,\n",
    "                hidden_cell=None,\n",
    "                trainable_theta=False,\n",
    "                input_to_hidden=False,\n",
    "                hidden_to_memory=False,\n",
    "                memory_to_memory=False,\n",
    "                discretizer=discretizer,\n",
    "                kernel_initializer=None,\n",
    "                trainable=False,\n",
    "            ),\n",
    "            return_sequences=True,\n",
    "        )\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \"\"\"\n",
    "        Builds the layer.\n",
    "        Notes\n",
    "        -----\n",
    "        This method should not be called manually; rather, use the implicit layer\n",
    "        callable behaviour (like ``my_layer(inputs)``), which will apply this method\n",
    "        with some additional bookkeeping.\n",
    "        \"\"\"\n",
    "\n",
    "        super().build(input_shape)\n",
    "\n",
    "        seq_len = input_shape[1]\n",
    "        enc_d = input_shape[-1]\n",
    "\n",
    "        if seq_len is None:\n",
    "            # TODO: we could dynamically run the impulse response for longer if\n",
    "            #  needed using stateful=True\n",
    "            raise ValueError(\n",
    "                f\"LMUFeedforward requires that the input shape's temporal axis be \"\n",
    "                f\"fully specified (got {seq_len})\"\n",
    "            )\n",
    "\n",
    "        impulse = tf.reshape(tf.eye(seq_len, 1), (1, -1, 1))\n",
    "\n",
    "        self.impulse_response = tf.squeeze(\n",
    "            self.delay_layer(impulse, training=False), axis=0\n",
    "        )\n",
    "\n",
    "        if self.conv_mode == \"fft\":\n",
    "            self.impulse_response = tf.signal.rfft(\n",
    "                tf.transpose(self.impulse_response),\n",
    "                fft_length=[2 * seq_len],\n",
    "            )\n",
    "        else:\n",
    "            if self.truncate_ir is not None:\n",
    "                assert self.impulse_response.shape == (seq_len, self.order)\n",
    "\n",
    "                cumsum = tf.math.cumsum(\n",
    "                    tf.math.abs(self.impulse_response), axis=0, reverse=True\n",
    "                )\n",
    "                cumsum = cumsum / cumsum[0]\n",
    "                to_drop = tf.reduce_all(cumsum < self.truncate_ir, axis=-1)\n",
    "                if to_drop[-1]:\n",
    "                    cutoff = tf.where(to_drop)[0, -1]\n",
    "                    self.impulse_response = self.impulse_response[:cutoff]\n",
    "\n",
    "            self.impulse_response = tf.reshape(\n",
    "                self.impulse_response,\n",
    "                (self.impulse_response.shape[0], 1, 1, self.order),\n",
    "            )\n",
    "            self.impulse_response = self.impulse_response[::-1, :, :, :]\n",
    "\n",
    "        if self.kernel_initializer is not None:\n",
    "            self.kernel = self.add_weight(\n",
    "                name=\"kernel\",\n",
    "                shape=(input_shape[-1], self.memory_d),\n",
    "                initializer=self.kernel_initializer,\n",
    "            )\n",
    "        else:\n",
    "            self.kernel = None\n",
    "            if enc_d != self.memory_d:\n",
    "                raise ValueError(\n",
    "                    f\"For LMUCells with no input kernel, the input dimension ({enc_d})\"\n",
    "                    f\" must equal `memory_d` ({self.memory_d}).\"\n",
    "                )\n",
    "\n",
    "        if self.hidden_cell is not None and not self.hidden_cell.built:\n",
    "            hidden_input_d = self.memory_d * self.order\n",
    "            if self.input_to_hidden:\n",
    "                hidden_input_d += input_shape[-1]\n",
    "            with tf.name_scope(self.hidden_cell.name):\n",
    "                self.hidden_cell.build((input_shape[0], hidden_input_d))\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        \"\"\"\n",
    "        Apply this layer to inputs.\n",
    "        Notes\n",
    "        -----\n",
    "        This method should not be called manually; rather, use the implicit layer\n",
    "        callable behaviour (like ``my_layer(inputs)``), which will apply this method\n",
    "        with some additional bookkeeping.\n",
    "        \"\"\"\n",
    "\n",
    "        if training is None:\n",
    "            training = tf.keras.backend.learning_phase()\n",
    "\n",
    "        if self.dropout:\n",
    "            inputs = tf.keras.layers.Dropout(\n",
    "                self.dropout, noise_shape=(inputs.shape[0], 1) + inputs.shape[2:]\n",
    "            )(inputs)\n",
    "\n",
    "        # Apply input encoders\n",
    "        u = (\n",
    "            inputs\n",
    "            if self.kernel is None\n",
    "            else tf.matmul(inputs, self.kernel, name=\"input_encoder_mult\")\n",
    "        )\n",
    "\n",
    "        if self.conv_mode == \"fft\":\n",
    "            m = self._fft_convolution(u)\n",
    "        elif self.conv_mode == \"raw\":\n",
    "            m = self._raw_convolution(u)\n",
    "\n",
    "        # apply hidden cell\n",
    "        h_in = tf.concat((m, inputs), axis=-1) if self.input_to_hidden else m\n",
    "\n",
    "        if self.hidden_cell is None:\n",
    "            h = h_in if self.return_sequences else h_in[:, -1]\n",
    "        elif hasattr(self.hidden_cell, \"state_size\"):\n",
    "            h = tf.keras.layers.RNN(\n",
    "                self.hidden_cell, return_sequences=self.return_sequences\n",
    "            )(h_in, training=training)\n",
    "        else:\n",
    "            if not self.return_sequences:\n",
    "                # no point applying the hidden cell to the whole sequence\n",
    "                h = self.hidden_cell(h_in[:, -1], training=training)\n",
    "            else:\n",
    "                h = tf.keras.layers.TimeDistributed(self.hidden_cell)(\n",
    "                    h_in, training=training\n",
    "                )\n",
    "\n",
    "        return h\n",
    "\n",
    "    def _fft_convolution(self, u):\n",
    "        seq_len = tf.shape(u)[1]\n",
    "\n",
    "        # FFT requires shape (batch, memory_d, timesteps)\n",
    "        u = tf.transpose(u, perm=[0, 2, 1])\n",
    "\n",
    "        # Pad sequences to avoid circular convolution\n",
    "        # Perform the FFT\n",
    "        fft_input = tf.signal.rfft(u, fft_length=[2 * seq_len])\n",
    "\n",
    "        # Elementwise product of FFT (with broadcasting)\n",
    "        result = tf.expand_dims(fft_input, axis=-2) * self.impulse_response\n",
    "\n",
    "        # Inverse FFT\n",
    "        m = tf.signal.irfft(result, fft_length=[2 * seq_len])[..., :seq_len]\n",
    "\n",
    "        m = tf.reshape(m, (-1, self.order * self.memory_d, seq_len))\n",
    "\n",
    "        return tf.transpose(m, perm=[0, 2, 1])\n",
    "\n",
    "    def _raw_convolution(self, u):\n",
    "        seq_len = tf.shape(u)[1]\n",
    "        ir_len = self.impulse_response.shape[0]\n",
    "\n",
    "        u = tf.expand_dims(u, -1)\n",
    "        m = tf.nn.conv2d(\n",
    "            u,\n",
    "            self.impulse_response,\n",
    "            strides=1,\n",
    "            data_format=\"NHWC\",\n",
    "            padding=[[0, 0], [ir_len - 1, 0], [0, 0], [0, 0]],\n",
    "        )\n",
    "        m = tf.reshape(m, (-1, seq_len, self.memory_d * self.order))\n",
    "        return m\n",
    "\n",
    "    def get_config(self):\n",
    "        \"\"\"Return config of layer (for serialization during model saving/loading).\"\"\"\n",
    "\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            dict(\n",
    "                memory_d=self.memory_d,\n",
    "                order=self.order,\n",
    "                theta=self.theta,\n",
    "                hidden_cell=tf.keras.layers.serialize(self.hidden_cell),\n",
    "                input_to_hidden=self.input_to_hidden,\n",
    "                discretizer=self.discretizer,\n",
    "                kernel_initializer=self.kernel_initializer,\n",
    "                dropout=self.dropout,\n",
    "                return_sequences=self.return_sequences,\n",
    "                conv_mode=self.conv_mode,\n",
    "                truncate_ir=self.truncate_ir,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        \"\"\"Load model from serialized config.\"\"\"\n",
    "\n",
    "        config[\"hidden_cell\"] = tf.keras.layers.deserialize(config[\"hidden_cell\"])\n",
    "        return super().from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-louis",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# set seed to ensure the examples are reproducible\n",
    "seed = 0\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-childhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dec = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-story",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_type = 'lmu'\n",
    "\n",
    "device = 'watch'\n",
    "subset = 2\n",
    "time_window = 2\n",
    "\n",
    "window_size = 20*time_window # 20 Hz sampling times the temporal length of the window\n",
    "\n",
    "datafile = 'data_'+device+'_subset'+str(subset)+'_'+str(window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-chick",
   "metadata": {},
   "outputs": [],
   "source": [
    "if freq_dec:\n",
    "    model_name = \"LMU_freqdec_{}_subset{}_{}\".format(device,subset_window_size)\n",
    "else:\n",
    "    model_name = \"LMU_{}_subset{}_{}\".format(device,subset_window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-smith",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### GET NETWORK STRUCTURE PARAMETERS #####\n",
    "optim_nni_experiment = ''\n",
    "optim_nni_trial = ''\n",
    "optim_filename = 'parameter.cfg'\n",
    "optim_nni_ref = 'nni-experiments/'+optim_nni_experiment+'/trials/'+optim_nni_trial\n",
    "optim_nni_dir = os.path.expanduser('~')\n",
    "optim_filepath = os.path.join(optim_nni_dir,optim_nni_ref,optim_filename)\n",
    "\n",
    "with open(optim_filepath, 'r') as f:\n",
    "    data = f.read()\n",
    "\n",
    "params = json.loads(data)\n",
    "network_parameters = params['parameters']\n",
    "\n",
    "minibatch_train = network_parameters['minibatch']\n",
    "###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-population",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, x_val, x_test, y_train_oh, y_val_oh, y_test_oh) = load_wisdm2_data(datafile)\n",
    "\n",
    "if freq_dec:\n",
    "    from scipy.signal import butter\n",
    "    x_train = frequency_decomposition(x_train)\n",
    "    x_val = frequency_decomposition(x_val)\n",
    "    x_test = frequency_decomposition(x_test)\n",
    "\n",
    "timesteps = len(x_train[0])\n",
    "input_dim = len(x_train[0][0])\n",
    "n_classes = len(y_train_oh[0])\n",
    "\n",
    "y_train = np.argmax(y_train_oh, axis=-1)\n",
    "y_val = np.argmax(y_val_oh, axis=-1)\n",
    "y_test = np.argmax(y_test_oh, axis=-1)\n",
    "\n",
    "print('timesteps:',timesteps)\n",
    "print('input_dim:',input_dim)\n",
    "print('n_classes:',n_classes)\n",
    "\n",
    "y_train = y_train[:, None, None]\n",
    "y_test = y_test[:, None, None]\n",
    "y_val = y_val[:, None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c68761f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Input((timesteps,input_dim)))\n",
    "model.add(LMU(memory_d=1,\n",
    "              order=int(network_parameters['order']),\n",
    "              theta=network_parameters['theta'],\n",
    "              hidden_cell=tf.keras.layers.SimpleRNNCell(units=int(network_parameters['units'])),\n",
    "              hidden_to_memory=False,\n",
    "              memory_to_memory=True,\n",
    "              input_to_hidden=True,\n",
    "              tau=network_parameters['tau'],\n",
    "             )\n",
    "         )\n",
    "model.add(Dense(n_classes, use_bias=False))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sorted-knitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"FLOPs: {}\".format(get_flops(model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olympic-depression",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy = get_flops(model)*7.53e-10 # Event-Driven Signal Processing with Neuromorphic Computing Systems, https://ieeexplore.ieee.org/document/9053043/\n",
    "\n",
    "print(\"Energy evaluation on Movidius: \"+str(np.round(energy*1e6,2))+\" μJ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-multimedia",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
